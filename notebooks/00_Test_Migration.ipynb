{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test de Migration - Nouvelle Structure Modulaire\n",
    "\n",
    "Ce notebook teste la nouvelle structure modulaire du projet STA211."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test de la configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 13:52:57,602 - modules.config - INFO - ✅ Configuration chargée depuis config.py\n",
      "2025-08-14 13:52:57,602 - modules.config - INFO - 📁 Racine du projet: c:\\sta211-project\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration chargée\n",
      "📁 Racine du projet: c:\\sta211-project\n",
      "🏷️ Nom du projet: STA211 Ads\n",
      "👤 Auteur: Maoulida Abdoullatuf\n",
      "📊 Random state: 42\n",
      "\n",
      "📂 Chemins configurés:\n",
      "  ✅ data: c:\\sta211-project\\data\n",
      "  ❌ raw: c:\\sta211-project\\data\\raw\n",
      "  ✅ processed: c:\\sta211-project\\data\\processed\n",
      "  ✅ outputs: c:\\sta211-project\\outputs\n",
      "  ✅ figures: c:\\sta211-project\\outputs\\figures\n",
      "  ✅ models: c:\\sta211-project\\artifacts\\models\n",
      "  ✅ imputers: c:\\sta211-project\\artifacts\\imputers\n",
      "  ✅ transformers: c:\\sta211-project\\artifacts\\transformers\n"
     ]
    }
   ],
   "source": [
    "# Import de la configuration\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from modules.config import cfg\n",
    "\n",
    "print(\"✅ Configuration chargée\")\n",
    "print(f\"📁 Racine du projet: {cfg.root}\")\n",
    "print(f\"🏷️ Nom du projet: {cfg.project.project_name}\")\n",
    "print(f\"👤 Auteur: {cfg.project.author}\")\n",
    "print(f\"📊 Random state: {cfg.project.random_state}\")\n",
    "\n",
    "print(\"\\n📂 Chemins configurés:\")\n",
    "for attr_name in ['data', 'raw', 'processed', 'outputs', 'figures', 'models', 'imputers', 'transformers']:\n",
    "    path = getattr(cfg.paths, attr_name)\n",
    "    exists = \"✅\" if path.exists() else \"❌\"\n",
    "    print(f\"  {exists} {attr_name}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test des utilitaires de stockage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 13:52:57,618 - modules.utils.storage - INFO - ✅ Sauvegarde de c:\\sta211-project\\artifacts\\models\\test_artifact.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Utilitaires de stockage importés\n",
      "💾 Données sauvegardées: c:\\sta211-project\\artifacts\\models\\test_artifact.pkl\n",
      "🔍 Artefact existe: True\n",
      "📂 Données rechargées: {'test': 'data', 'array': array([1, 2, 3])}\n",
      "✅ Intégrité des données: True\n"
     ]
    }
   ],
   "source": [
    "from modules.utils import save_artifact, load_artifact, artifact_exists\n",
    "import numpy as np\n",
    "\n",
    "print(\"✅ Utilitaires de stockage importés\")\n",
    "\n",
    "# Test de sauvegarde/rechargement\n",
    "test_data = {'test': 'data', 'array': np.array([1, 2, 3])}\n",
    "test_filename = \"test_artifact.pkl\"\n",
    "\n",
    "# Sauvegarder\n",
    "saved_path = save_artifact(test_data, test_filename, cfg.paths.models)\n",
    "print(f\"💾 Données sauvegardées: {saved_path}\")\n",
    "\n",
    "# Vérifier existence\n",
    "exists = artifact_exists(test_filename, cfg.paths.models)\n",
    "print(f\"🔍 Artefact existe: {exists}\")\n",
    "\n",
    "# Recharger\n",
    "loaded_data = load_artifact(test_filename, cfg.paths.models)\n",
    "print(f\"📂 Données rechargées: {loaded_data}\")\n",
    "\n",
    "# Vérifier intégrité\n",
    "integrity_check = (\n",
    "    loaded_data['test'] == test_data['test'] and \n",
    "    np.array_equal(loaded_data['array'], test_data['array'])\n",
    ")\n",
    "print(f\"✅ Intégrité des données: {integrity_check}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test du module de prétraitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Module de prétraitement importé\n",
      "📦 Fonctions disponibles:\n",
      "  - load_and_clean_data\n",
      "  - perform_knn_imputation\n",
      "  - apply_optimal_transformations\n",
      "  - detect_and_cap_outliers\n",
      "\n",
      "📊 Données de test créées: (100, 3)\n",
      "🕳️ Valeurs manquantes: 10\n",
      "🔧 IMPUTATION KNN (k=5)\n",
      "========================================\n",
      "  • feature1: 10 valeurs manquantes (10.0%)\n",
      "✅ Imputation terminée en 0.01s\n",
      "🎯 Colonnes imputées: 1\n",
      "✅ Toutes les valeurs manquantes ont été imputées\n",
      "✅ Imputation KNN: 0 valeurs manquantes restantes\n"
     ]
    }
   ],
   "source": [
    "from modules.notebook1_preprocessing import (\n",
    "    load_and_clean_data,\n",
    "    perform_knn_imputation,\n",
    "    apply_optimal_transformations,\n",
    "    detect_and_cap_outliers\n",
    ")\n",
    "\n",
    "print(\"✅ Module de prétraitement importé\")\n",
    "print(\"📦 Fonctions disponibles:\")\n",
    "print(\"  - load_and_clean_data\")\n",
    "print(\"  - perform_knn_imputation\")\n",
    "print(\"  - apply_optimal_transformations\")\n",
    "print(\"  - detect_and_cap_outliers\")\n",
    "\n",
    "# Test avec des données factices\n",
    "import pandas as pd\n",
    "np.random.seed(42)\n",
    "\n",
    "# Créer des données de test\n",
    "n_samples = 100\n",
    "test_df = pd.DataFrame({\n",
    "    'feature1': np.random.normal(0, 1, n_samples),\n",
    "    'feature2': np.random.normal(5, 2, n_samples),\n",
    "    'target': np.random.binomial(1, 0.3, n_samples)\n",
    "})\n",
    "\n",
    "# Introduire quelques valeurs manquantes\n",
    "missing_idx = np.random.choice(n_samples, 10, replace=False)\n",
    "test_df.loc[missing_idx, 'feature1'] = np.nan\n",
    "\n",
    "print(f\"\\n📊 Données de test créées: {test_df.shape}\")\n",
    "print(f\"🕳️ Valeurs manquantes: {test_df.isnull().sum().sum()}\")\n",
    "\n",
    "# Test KNN imputation\n",
    "df_imputed, imputer = perform_knn_imputation(\n",
    "    test_df, ['feature1'], n_neighbors=5, save_imputer=False\n",
    ")\n",
    "\n",
    "remaining_missing = df_imputed.isnull().sum().sum()\n",
    "print(f\"✅ Imputation KNN: {remaining_missing} valeurs manquantes restantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test du module de modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Module de modélisation importé\n",
      "\n",
      "📋 Grilles de paramètres disponibles: ['randforest', 'xgboost', 'gradboost', 'svm', 'mlp']\n",
      "🤖 Estimateurs disponibles: ['randforest', 'xgboost', 'gradboost', 'svm', 'mlp']\n",
      "\n",
      "🎯 Seuil optimal: 0.100\n",
      "📈 Score F1 optimal: 0.451\n"
     ]
    }
   ],
   "source": [
    "from modules.notebook2_modeling import (\n",
    "    get_default_param_grids,\n",
    "    create_model_estimators,\n",
    "    optimize_classification_threshold\n",
    ")\n",
    "\n",
    "print(\"✅ Module de modélisation importé\")\n",
    "\n",
    "# Test des grilles de paramètres\n",
    "param_grids = get_default_param_grids()\n",
    "print(f\"\\n📋 Grilles de paramètres disponibles: {list(param_grids.keys())}\")\n",
    "\n",
    "# Test des estimateurs\n",
    "estimators = create_model_estimators()\n",
    "print(f\"🤖 Estimateurs disponibles: {list(estimators.keys())}\")\n",
    "\n",
    "# Test d'optimisation de seuil avec des données factices\n",
    "y_true = np.random.binomial(1, 0.3, 1000)\n",
    "y_proba = np.random.beta(2, 5, 1000)  # Probabilités factices\n",
    "\n",
    "threshold_results = optimize_classification_threshold(\n",
    "    y_true, y_proba, metric='f1', verbose=False\n",
    ")\n",
    "\n",
    "print(f\"\\n🎯 Seuil optimal: {threshold_results['best_threshold']:.3f}\")\n",
    "print(f\"📈 Score F1 optimal: {threshold_results['best_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test du module d'ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 13:53:00,548 - modules.modeling.ensembles - INFO - 🗳️ Création d'un ensemble Voting (soft)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Module d'ensembles importé\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 13:53:00,548 - modules.modeling.ensembles - INFO - 📊 Modèles de base: ['rf', 'svm', 'lr']\n",
      "2025-08-14 13:53:00,548 - modules.modeling.ensembles - INFO - 🥞 Création d'un ensemble Stacking\n",
      "2025-08-14 13:53:00,548 - modules.modeling.ensembles - INFO - 📊 Modèles de base: ['rf', 'svm', 'lr']\n",
      "2025-08-14 13:53:00,548 - modules.modeling.ensembles - INFO - 🧠 Méta-classificateur: LogisticRegression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗳️ Voting Ensemble créé: VotingClassifier\n",
      "🥞 Stacking Ensemble créé: StackingClassifier\n",
      "\n",
      "📦 Fonctions d'ensemble disponibles:\n",
      "  - create_voting_ensemble\n",
      "  - create_bagging_ensemble\n",
      "  - create_stacking_ensemble\n",
      "  - optimize_ensemble\n",
      "  - train_all_ensembles\n"
     ]
    }
   ],
   "source": [
    "from modules.modeling import (\n",
    "    create_voting_ensemble,\n",
    "    create_stacking_ensemble,\n",
    "    get_ensemble_feature_importance\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(\"✅ Module d'ensembles importé\")\n",
    "\n",
    "# Créer des modèles de base pour test\n",
    "base_models = {\n",
    "    'rf': RandomForestClassifier(n_estimators=10, random_state=42),\n",
    "    'svm': SVC(probability=True, random_state=42),\n",
    "    'lr': LogisticRegression(random_state=42)\n",
    "}\n",
    "\n",
    "# Test Voting Ensemble\n",
    "voting_ensemble = create_voting_ensemble(base_models, voting='soft')\n",
    "print(f\"🗳️ Voting Ensemble créé: {type(voting_ensemble).__name__}\")\n",
    "\n",
    "# Test Stacking Ensemble\n",
    "stacking_ensemble = create_stacking_ensemble(base_models)\n",
    "print(f\"🥞 Stacking Ensemble créé: {type(stacking_ensemble).__name__}\")\n",
    "\n",
    "print(\"\\n📦 Fonctions d'ensemble disponibles:\")\n",
    "print(\"  - create_voting_ensemble\")\n",
    "print(\"  - create_bagging_ensemble\")\n",
    "print(\"  - create_stacking_ensemble\")\n",
    "print(\"  - optimize_ensemble\")\n",
    "print(\"  - train_all_ensembles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test du module d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 13:53:00,598 - modules.evaluation.metrics - INFO - 🎯 Optimisation du seuil pour f1\n",
      "2025-08-14 13:53:00,732 - modules.evaluation.metrics - INFO - 🏆 Seuil optimal: 0.210 (score: 0.5225)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Module d'évaluation importé\n",
      "\n",
      "📊 Métriques de base calculées: ['accuracy', 'precision', 'recall', 'f1', 'specificity', 'npv', 'auc_roc', 'auc_pr']\n",
      "   F1-Score: 0.413\n",
      "   AUC-ROC: 0.5300797030243476\n",
      "\n",
      "📈 Métriques détaillées disponibles: ['basic_metrics', 'classification_report', 'confusion_matrix', 'confusion_matrix_normalized']\n",
      "\n",
      "🎯 Optimisation de seuil:\n",
      "   Seuil optimal: 0.210\n",
      "   Score optimal: 0.523\n",
      "\n",
      "📋 Fonctions d'évaluation disponibles:\n",
      "  - calculate_basic_metrics\n",
      "  - calculate_detailed_metrics\n",
      "  - optimize_threshold\n",
      "  - analyze_threshold_sensitivity\n",
      "  - plot_evaluation_dashboard\n",
      "  - generate_evaluation_report\n"
     ]
    }
   ],
   "source": [
    "from modules.evaluation import (\n",
    "    calculate_basic_metrics,\n",
    "    calculate_detailed_metrics,\n",
    "    optimize_threshold,\n",
    "    generate_evaluation_report\n",
    ")\n",
    "\n",
    "print(\"✅ Module d'évaluation importé\")\n",
    "\n",
    "# Test avec des prédictions factices\n",
    "y_true = np.random.binomial(1, 0.4, 200)\n",
    "y_pred = np.random.binomial(1, 0.4, 200)\n",
    "y_proba = np.random.beta(2, 3, 200)\n",
    "\n",
    "# Test des métriques de base\n",
    "basic_metrics = calculate_basic_metrics(y_true, y_pred, y_proba)\n",
    "print(f\"\\n📊 Métriques de base calculées: {list(basic_metrics.keys())}\")\n",
    "print(f\"   F1-Score: {basic_metrics['f1']:.3f}\")\n",
    "print(f\"   AUC-ROC: {basic_metrics.get('auc_roc', 'N/A')}\")\n",
    "\n",
    "# Test des métriques détaillées\n",
    "detailed_metrics = calculate_detailed_metrics(y_true, y_pred, y_proba)\n",
    "print(f\"\\n📈 Métriques détaillées disponibles: {list(detailed_metrics.keys())}\")\n",
    "\n",
    "# Test d'optimisation de seuil\n",
    "threshold_opt = optimize_threshold(y_true, y_proba, metric='f1')\n",
    "print(f\"\\n🎯 Optimisation de seuil:\")\n",
    "print(f\"   Seuil optimal: {threshold_opt['best_threshold']:.3f}\")\n",
    "print(f\"   Score optimal: {threshold_opt['best_score']:.3f}\")\n",
    "\n",
    "print(\"\\n📋 Fonctions d'évaluation disponibles:\")\n",
    "print(\"  - calculate_basic_metrics\")\n",
    "print(\"  - calculate_detailed_metrics\") \n",
    "print(\"  - optimize_threshold\")\n",
    "print(\"  - analyze_threshold_sensitivity\")\n",
    "print(\"  - plot_evaluation_dashboard\")\n",
    "print(\"  - generate_evaluation_report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test de génération de rapport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 13:53:00,757 - modules.evaluation.metrics - INFO - 📝 Génération du rapport pour TestModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Rapport d'évaluation généré:\n",
      "==================================================\n",
      "================================================================================\n",
      "RAPPORT D'ÉVALUATION - TESTMODEL\n",
      "================================================================================\n",
      "\n",
      "MÉTRIQUES PRINCIPALES:\n",
      "------------------------------\n",
      "ACCURACY       : 0.5600\n",
      "PRECISION      : 0.3924\n",
      "RECALL         : 0.4366\n",
      "F1             : 0.4133\n",
      "SPECIFICITY    : 0.6279\n",
      "NPV            : 0.6694\n",
      "AUC_ROC        : 0.5301\n",
      "AUC_PR         : 0.3874\n",
      "\n",
      "RAPPORT DE CLASSIFICATION:\n",
      "------------------------------...\n"
     ]
    }
   ],
   "source": [
    "# Simulation des résultats d'un modèle\n",
    "model_results = {\n",
    "    'basic_metrics': basic_metrics,\n",
    "    'classification_report': detailed_metrics['classification_report'],\n",
    "    'confusion_matrix': detailed_metrics['confusion_matrix'],\n",
    "    'optimal_threshold': threshold_opt,\n",
    "    'training_time': 45.2,\n",
    "    'best_cv_score': 0.742\n",
    "}\n",
    "\n",
    "# Générer un rapport\n",
    "report = generate_evaluation_report(\n",
    "    model_results, \n",
    "    model_name=\"TestModel\", \n",
    "    save_report=False\n",
    ")\n",
    "\n",
    "print(\"📝 Rapport d'évaluation généré:\")\n",
    "print(\"=\" * 50)\n",
    "print(report[:500] + \"...\" if len(report) > 500 else report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Résumé des tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 RÉSUMÉ DES TESTS DE MIGRATION\n",
      "==================================================\n",
      "✅ Configuration centralisée\n",
      "✅ Utilitaires de stockage\n",
      "✅ Module de prétraitement (Notebook 1)\n",
      "✅ Module de modélisation (Notebook 2)\n",
      "✅ Module d'ensembles (Notebook 3)\n",
      "✅ Module d'évaluation\n",
      "✅ Génération de rapports\n",
      "\n",
      "🚀 La migration vers la nouvelle structure modulaire est RÉUSSIE !\n",
      "\n",
      "📖 Consultez MIGRATION_GUIDE.md pour les détails d'utilisation.\n"
     ]
    }
   ],
   "source": [
    "print(\"🎉 RÉSUMÉ DES TESTS DE MIGRATION\")\n",
    "print(\"=\" * 50)\n",
    "print(\"✅ Configuration centralisée\")\n",
    "print(\"✅ Utilitaires de stockage\")\n",
    "print(\"✅ Module de prétraitement (Notebook 1)\")\n",
    "print(\"✅ Module de modélisation (Notebook 2)\")\n",
    "print(\"✅ Module d'ensembles (Notebook 3)\")\n",
    "print(\"✅ Module d'évaluation\")\n",
    "print(\"✅ Génération de rapports\")\n",
    "print(\"\\n🚀 La migration vers la nouvelle structure modulaire est RÉUSSIE !\")\n",
    "print(\"\\n📖 Consultez MIGRATION_GUIDE.md pour les détails d'utilisation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sta211_colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
