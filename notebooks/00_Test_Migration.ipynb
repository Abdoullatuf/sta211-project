{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test de Migration - Nouvelle Structure Modulaire\n",
    "\n",
    "Ce notebook teste la nouvelle structure modulaire du projet STA211."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Test de la configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 13:52:57,602 - modules.config - INFO - âœ… Configuration chargÃ©e depuis config.py\n",
      "2025-08-14 13:52:57,602 - modules.config - INFO - ðŸ“ Racine du projet: c:\\sta211-project\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Configuration chargÃ©e\n",
      "ðŸ“ Racine du projet: c:\\sta211-project\n",
      "ðŸ·ï¸ Nom du projet: STA211 Ads\n",
      "ðŸ‘¤ Auteur: Maoulida Abdoullatuf\n",
      "ðŸ“Š Random state: 42\n",
      "\n",
      "ðŸ“‚ Chemins configurÃ©s:\n",
      "  âœ… data: c:\\sta211-project\\data\n",
      "  âŒ raw: c:\\sta211-project\\data\\raw\n",
      "  âœ… processed: c:\\sta211-project\\data\\processed\n",
      "  âœ… outputs: c:\\sta211-project\\outputs\n",
      "  âœ… figures: c:\\sta211-project\\outputs\\figures\n",
      "  âœ… models: c:\\sta211-project\\artifacts\\models\n",
      "  âœ… imputers: c:\\sta211-project\\artifacts\\imputers\n",
      "  âœ… transformers: c:\\sta211-project\\artifacts\\transformers\n"
     ]
    }
   ],
   "source": [
    "# Import de la configuration\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from modules.config import cfg\n",
    "\n",
    "print(\"âœ… Configuration chargÃ©e\")\n",
    "print(f\"ðŸ“ Racine du projet: {cfg.root}\")\n",
    "print(f\"ðŸ·ï¸ Nom du projet: {cfg.project.project_name}\")\n",
    "print(f\"ðŸ‘¤ Auteur: {cfg.project.author}\")\n",
    "print(f\"ðŸ“Š Random state: {cfg.project.random_state}\")\n",
    "\n",
    "print(\"\\nðŸ“‚ Chemins configurÃ©s:\")\n",
    "for attr_name in ['data', 'raw', 'processed', 'outputs', 'figures', 'models', 'imputers', 'transformers']:\n",
    "    path = getattr(cfg.paths, attr_name)\n",
    "    exists = \"âœ…\" if path.exists() else \"âŒ\"\n",
    "    print(f\"  {exists} {attr_name}: {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test des utilitaires de stockage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 13:52:57,618 - modules.utils.storage - INFO - âœ… Sauvegarde de c:\\sta211-project\\artifacts\\models\\test_artifact.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Utilitaires de stockage importÃ©s\n",
      "ðŸ’¾ DonnÃ©es sauvegardÃ©es: c:\\sta211-project\\artifacts\\models\\test_artifact.pkl\n",
      "ðŸ” Artefact existe: True\n",
      "ðŸ“‚ DonnÃ©es rechargÃ©es: {'test': 'data', 'array': array([1, 2, 3])}\n",
      "âœ… IntÃ©gritÃ© des donnÃ©es: True\n"
     ]
    }
   ],
   "source": [
    "from modules.utils import save_artifact, load_artifact, artifact_exists\n",
    "import numpy as np\n",
    "\n",
    "print(\"âœ… Utilitaires de stockage importÃ©s\")\n",
    "\n",
    "# Test de sauvegarde/rechargement\n",
    "test_data = {'test': 'data', 'array': np.array([1, 2, 3])}\n",
    "test_filename = \"test_artifact.pkl\"\n",
    "\n",
    "# Sauvegarder\n",
    "saved_path = save_artifact(test_data, test_filename, cfg.paths.models)\n",
    "print(f\"ðŸ’¾ DonnÃ©es sauvegardÃ©es: {saved_path}\")\n",
    "\n",
    "# VÃ©rifier existence\n",
    "exists = artifact_exists(test_filename, cfg.paths.models)\n",
    "print(f\"ðŸ” Artefact existe: {exists}\")\n",
    "\n",
    "# Recharger\n",
    "loaded_data = load_artifact(test_filename, cfg.paths.models)\n",
    "print(f\"ðŸ“‚ DonnÃ©es rechargÃ©es: {loaded_data}\")\n",
    "\n",
    "# VÃ©rifier intÃ©gritÃ©\n",
    "integrity_check = (\n",
    "    loaded_data['test'] == test_data['test'] and \n",
    "    np.array_equal(loaded_data['array'], test_data['array'])\n",
    ")\n",
    "print(f\"âœ… IntÃ©gritÃ© des donnÃ©es: {integrity_check}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test du module de prÃ©traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Module de prÃ©traitement importÃ©\n",
      "ðŸ“¦ Fonctions disponibles:\n",
      "  - load_and_clean_data\n",
      "  - perform_knn_imputation\n",
      "  - apply_optimal_transformations\n",
      "  - detect_and_cap_outliers\n",
      "\n",
      "ðŸ“Š DonnÃ©es de test crÃ©Ã©es: (100, 3)\n",
      "ðŸ•³ï¸ Valeurs manquantes: 10\n",
      "ðŸ”§ IMPUTATION KNN (k=5)\n",
      "========================================\n",
      "  â€¢ feature1: 10 valeurs manquantes (10.0%)\n",
      "âœ… Imputation terminÃ©e en 0.01s\n",
      "ðŸŽ¯ Colonnes imputÃ©es: 1\n",
      "âœ… Toutes les valeurs manquantes ont Ã©tÃ© imputÃ©es\n",
      "âœ… Imputation KNN: 0 valeurs manquantes restantes\n"
     ]
    }
   ],
   "source": [
    "from modules.notebook1_preprocessing import (\n",
    "    load_and_clean_data,\n",
    "    perform_knn_imputation,\n",
    "    apply_optimal_transformations,\n",
    "    detect_and_cap_outliers\n",
    ")\n",
    "\n",
    "print(\"âœ… Module de prÃ©traitement importÃ©\")\n",
    "print(\"ðŸ“¦ Fonctions disponibles:\")\n",
    "print(\"  - load_and_clean_data\")\n",
    "print(\"  - perform_knn_imputation\")\n",
    "print(\"  - apply_optimal_transformations\")\n",
    "print(\"  - detect_and_cap_outliers\")\n",
    "\n",
    "# Test avec des donnÃ©es factices\n",
    "import pandas as pd\n",
    "np.random.seed(42)\n",
    "\n",
    "# CrÃ©er des donnÃ©es de test\n",
    "n_samples = 100\n",
    "test_df = pd.DataFrame({\n",
    "    'feature1': np.random.normal(0, 1, n_samples),\n",
    "    'feature2': np.random.normal(5, 2, n_samples),\n",
    "    'target': np.random.binomial(1, 0.3, n_samples)\n",
    "})\n",
    "\n",
    "# Introduire quelques valeurs manquantes\n",
    "missing_idx = np.random.choice(n_samples, 10, replace=False)\n",
    "test_df.loc[missing_idx, 'feature1'] = np.nan\n",
    "\n",
    "print(f\"\\nðŸ“Š DonnÃ©es de test crÃ©Ã©es: {test_df.shape}\")\n",
    "print(f\"ðŸ•³ï¸ Valeurs manquantes: {test_df.isnull().sum().sum()}\")\n",
    "\n",
    "# Test KNN imputation\n",
    "df_imputed, imputer = perform_knn_imputation(\n",
    "    test_df, ['feature1'], n_neighbors=5, save_imputer=False\n",
    ")\n",
    "\n",
    "remaining_missing = df_imputed.isnull().sum().sum()\n",
    "print(f\"âœ… Imputation KNN: {remaining_missing} valeurs manquantes restantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test du module de modÃ©lisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Module de modÃ©lisation importÃ©\n",
      "\n",
      "ðŸ“‹ Grilles de paramÃ¨tres disponibles: ['randforest', 'xgboost', 'gradboost', 'svm', 'mlp']\n",
      "ðŸ¤– Estimateurs disponibles: ['randforest', 'xgboost', 'gradboost', 'svm', 'mlp']\n",
      "\n",
      "ðŸŽ¯ Seuil optimal: 0.100\n",
      "ðŸ“ˆ Score F1 optimal: 0.451\n"
     ]
    }
   ],
   "source": [
    "from modules.notebook2_modeling import (\n",
    "    get_default_param_grids,\n",
    "    create_model_estimators,\n",
    "    optimize_classification_threshold\n",
    ")\n",
    "\n",
    "print(\"âœ… Module de modÃ©lisation importÃ©\")\n",
    "\n",
    "# Test des grilles de paramÃ¨tres\n",
    "param_grids = get_default_param_grids()\n",
    "print(f\"\\nðŸ“‹ Grilles de paramÃ¨tres disponibles: {list(param_grids.keys())}\")\n",
    "\n",
    "# Test des estimateurs\n",
    "estimators = create_model_estimators()\n",
    "print(f\"ðŸ¤– Estimateurs disponibles: {list(estimators.keys())}\")\n",
    "\n",
    "# Test d'optimisation de seuil avec des donnÃ©es factices\n",
    "y_true = np.random.binomial(1, 0.3, 1000)\n",
    "y_proba = np.random.beta(2, 5, 1000)  # ProbabilitÃ©s factices\n",
    "\n",
    "threshold_results = optimize_classification_threshold(\n",
    "    y_true, y_proba, metric='f1', verbose=False\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Seuil optimal: {threshold_results['best_threshold']:.3f}\")\n",
    "print(f\"ðŸ“ˆ Score F1 optimal: {threshold_results['best_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test du module d'ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 13:53:00,548 - modules.modeling.ensembles - INFO - ðŸ—³ï¸ CrÃ©ation d'un ensemble Voting (soft)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Module d'ensembles importÃ©\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 13:53:00,548 - modules.modeling.ensembles - INFO - ðŸ“Š ModÃ¨les de base: ['rf', 'svm', 'lr']\n",
      "2025-08-14 13:53:00,548 - modules.modeling.ensembles - INFO - ðŸ¥ž CrÃ©ation d'un ensemble Stacking\n",
      "2025-08-14 13:53:00,548 - modules.modeling.ensembles - INFO - ðŸ“Š ModÃ¨les de base: ['rf', 'svm', 'lr']\n",
      "2025-08-14 13:53:00,548 - modules.modeling.ensembles - INFO - ðŸ§  MÃ©ta-classificateur: LogisticRegression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—³ï¸ Voting Ensemble crÃ©Ã©: VotingClassifier\n",
      "ðŸ¥ž Stacking Ensemble crÃ©Ã©: StackingClassifier\n",
      "\n",
      "ðŸ“¦ Fonctions d'ensemble disponibles:\n",
      "  - create_voting_ensemble\n",
      "  - create_bagging_ensemble\n",
      "  - create_stacking_ensemble\n",
      "  - optimize_ensemble\n",
      "  - train_all_ensembles\n"
     ]
    }
   ],
   "source": [
    "from modules.modeling import (\n",
    "    create_voting_ensemble,\n",
    "    create_stacking_ensemble,\n",
    "    get_ensemble_feature_importance\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(\"âœ… Module d'ensembles importÃ©\")\n",
    "\n",
    "# CrÃ©er des modÃ¨les de base pour test\n",
    "base_models = {\n",
    "    'rf': RandomForestClassifier(n_estimators=10, random_state=42),\n",
    "    'svm': SVC(probability=True, random_state=42),\n",
    "    'lr': LogisticRegression(random_state=42)\n",
    "}\n",
    "\n",
    "# Test Voting Ensemble\n",
    "voting_ensemble = create_voting_ensemble(base_models, voting='soft')\n",
    "print(f\"ðŸ—³ï¸ Voting Ensemble crÃ©Ã©: {type(voting_ensemble).__name__}\")\n",
    "\n",
    "# Test Stacking Ensemble\n",
    "stacking_ensemble = create_stacking_ensemble(base_models)\n",
    "print(f\"ðŸ¥ž Stacking Ensemble crÃ©Ã©: {type(stacking_ensemble).__name__}\")\n",
    "\n",
    "print(\"\\nðŸ“¦ Fonctions d'ensemble disponibles:\")\n",
    "print(\"  - create_voting_ensemble\")\n",
    "print(\"  - create_bagging_ensemble\")\n",
    "print(\"  - create_stacking_ensemble\")\n",
    "print(\"  - optimize_ensemble\")\n",
    "print(\"  - train_all_ensembles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test du module d'Ã©valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 13:53:00,598 - modules.evaluation.metrics - INFO - ðŸŽ¯ Optimisation du seuil pour f1\n",
      "2025-08-14 13:53:00,732 - modules.evaluation.metrics - INFO - ðŸ† Seuil optimal: 0.210 (score: 0.5225)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Module d'Ã©valuation importÃ©\n",
      "\n",
      "ðŸ“Š MÃ©triques de base calculÃ©es: ['accuracy', 'precision', 'recall', 'f1', 'specificity', 'npv', 'auc_roc', 'auc_pr']\n",
      "   F1-Score: 0.413\n",
      "   AUC-ROC: 0.5300797030243476\n",
      "\n",
      "ðŸ“ˆ MÃ©triques dÃ©taillÃ©es disponibles: ['basic_metrics', 'classification_report', 'confusion_matrix', 'confusion_matrix_normalized']\n",
      "\n",
      "ðŸŽ¯ Optimisation de seuil:\n",
      "   Seuil optimal: 0.210\n",
      "   Score optimal: 0.523\n",
      "\n",
      "ðŸ“‹ Fonctions d'Ã©valuation disponibles:\n",
      "  - calculate_basic_metrics\n",
      "  - calculate_detailed_metrics\n",
      "  - optimize_threshold\n",
      "  - analyze_threshold_sensitivity\n",
      "  - plot_evaluation_dashboard\n",
      "  - generate_evaluation_report\n"
     ]
    }
   ],
   "source": [
    "from modules.evaluation import (\n",
    "    calculate_basic_metrics,\n",
    "    calculate_detailed_metrics,\n",
    "    optimize_threshold,\n",
    "    generate_evaluation_report\n",
    ")\n",
    "\n",
    "print(\"âœ… Module d'Ã©valuation importÃ©\")\n",
    "\n",
    "# Test avec des prÃ©dictions factices\n",
    "y_true = np.random.binomial(1, 0.4, 200)\n",
    "y_pred = np.random.binomial(1, 0.4, 200)\n",
    "y_proba = np.random.beta(2, 3, 200)\n",
    "\n",
    "# Test des mÃ©triques de base\n",
    "basic_metrics = calculate_basic_metrics(y_true, y_pred, y_proba)\n",
    "print(f\"\\nðŸ“Š MÃ©triques de base calculÃ©es: {list(basic_metrics.keys())}\")\n",
    "print(f\"   F1-Score: {basic_metrics['f1']:.3f}\")\n",
    "print(f\"   AUC-ROC: {basic_metrics.get('auc_roc', 'N/A')}\")\n",
    "\n",
    "# Test des mÃ©triques dÃ©taillÃ©es\n",
    "detailed_metrics = calculate_detailed_metrics(y_true, y_pred, y_proba)\n",
    "print(f\"\\nðŸ“ˆ MÃ©triques dÃ©taillÃ©es disponibles: {list(detailed_metrics.keys())}\")\n",
    "\n",
    "# Test d'optimisation de seuil\n",
    "threshold_opt = optimize_threshold(y_true, y_proba, metric='f1')\n",
    "print(f\"\\nðŸŽ¯ Optimisation de seuil:\")\n",
    "print(f\"   Seuil optimal: {threshold_opt['best_threshold']:.3f}\")\n",
    "print(f\"   Score optimal: {threshold_opt['best_score']:.3f}\")\n",
    "\n",
    "print(\"\\nðŸ“‹ Fonctions d'Ã©valuation disponibles:\")\n",
    "print(\"  - calculate_basic_metrics\")\n",
    "print(\"  - calculate_detailed_metrics\") \n",
    "print(\"  - optimize_threshold\")\n",
    "print(\"  - analyze_threshold_sensitivity\")\n",
    "print(\"  - plot_evaluation_dashboard\")\n",
    "print(\"  - generate_evaluation_report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test de gÃ©nÃ©ration de rapport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 13:53:00,757 - modules.evaluation.metrics - INFO - ðŸ“ GÃ©nÃ©ration du rapport pour TestModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Rapport d'Ã©valuation gÃ©nÃ©rÃ©:\n",
      "==================================================\n",
      "================================================================================\n",
      "RAPPORT D'Ã‰VALUATION - TESTMODEL\n",
      "================================================================================\n",
      "\n",
      "MÃ‰TRIQUES PRINCIPALES:\n",
      "------------------------------\n",
      "ACCURACY       : 0.5600\n",
      "PRECISION      : 0.3924\n",
      "RECALL         : 0.4366\n",
      "F1             : 0.4133\n",
      "SPECIFICITY    : 0.6279\n",
      "NPV            : 0.6694\n",
      "AUC_ROC        : 0.5301\n",
      "AUC_PR         : 0.3874\n",
      "\n",
      "RAPPORT DE CLASSIFICATION:\n",
      "------------------------------...\n"
     ]
    }
   ],
   "source": [
    "# Simulation des rÃ©sultats d'un modÃ¨le\n",
    "model_results = {\n",
    "    'basic_metrics': basic_metrics,\n",
    "    'classification_report': detailed_metrics['classification_report'],\n",
    "    'confusion_matrix': detailed_metrics['confusion_matrix'],\n",
    "    'optimal_threshold': threshold_opt,\n",
    "    'training_time': 45.2,\n",
    "    'best_cv_score': 0.742\n",
    "}\n",
    "\n",
    "# GÃ©nÃ©rer un rapport\n",
    "report = generate_evaluation_report(\n",
    "    model_results, \n",
    "    model_name=\"TestModel\", \n",
    "    save_report=False\n",
    ")\n",
    "\n",
    "print(\"ðŸ“ Rapport d'Ã©valuation gÃ©nÃ©rÃ©:\")\n",
    "print(\"=\" * 50)\n",
    "print(report[:500] + \"...\" if len(report) > 500 else report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. RÃ©sumÃ© des tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ RÃ‰SUMÃ‰ DES TESTS DE MIGRATION\n",
      "==================================================\n",
      "âœ… Configuration centralisÃ©e\n",
      "âœ… Utilitaires de stockage\n",
      "âœ… Module de prÃ©traitement (Notebook 1)\n",
      "âœ… Module de modÃ©lisation (Notebook 2)\n",
      "âœ… Module d'ensembles (Notebook 3)\n",
      "âœ… Module d'Ã©valuation\n",
      "âœ… GÃ©nÃ©ration de rapports\n",
      "\n",
      "ðŸš€ La migration vers la nouvelle structure modulaire est RÃ‰USSIE !\n",
      "\n",
      "ðŸ“– Consultez MIGRATION_GUIDE.md pour les dÃ©tails d'utilisation.\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸŽ‰ RÃ‰SUMÃ‰ DES TESTS DE MIGRATION\")\n",
    "print(\"=\" * 50)\n",
    "print(\"âœ… Configuration centralisÃ©e\")\n",
    "print(\"âœ… Utilitaires de stockage\")\n",
    "print(\"âœ… Module de prÃ©traitement (Notebook 1)\")\n",
    "print(\"âœ… Module de modÃ©lisation (Notebook 2)\")\n",
    "print(\"âœ… Module d'ensembles (Notebook 3)\")\n",
    "print(\"âœ… Module d'Ã©valuation\")\n",
    "print(\"âœ… GÃ©nÃ©ration de rapports\")\n",
    "print(\"\\nðŸš€ La migration vers la nouvelle structure modulaire est RÃ‰USSIE !\")\n",
    "print(\"\\nðŸ“– Consultez MIGRATION_GUIDE.md pour les dÃ©tails d'utilisation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sta211_colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
