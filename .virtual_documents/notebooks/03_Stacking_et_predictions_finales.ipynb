








import sys, os, logging
from pathlib import Path

# ‚îÄ‚îÄ 0. Logger clair (avec Rich si dispo)
try:
    from rich.logging import RichHandler
    logging.basicConfig(level="INFO",
                        format="%(message)s",
                        handlers=[RichHandler(rich_tracebacks=True, markup=True)],
                        force=True)
except ModuleNotFoundError:
    logging.basicConfig(level=logging.INFO,
                        format="%(asctime)s - %(levelname)s - %(message)s",
                        stream=sys.stdout,
                        force=True)
logger = logging.getLogger(__name__)

# ‚îÄ‚îÄ 1. D√©tection environnement Colab
def _in_colab() -> bool:
    try: import google.colab
    except ImportError: return False
    else: return True

# ‚îÄ‚îÄ 2. Montage Drive manuel rapide
if _in_colab():
    from google.colab import drive
    if not Path("/content/drive/MyDrive/Colab Notebooks").exists():
        logger.info("üîó Montage de Google Drive en cours‚Ä¶")
        drive.mount("/content/drive", force_remount=False)

# ‚îÄ‚îÄ 3. Localisation racine projet STA211
def find_project_root() -> Path:
    env_path = os.getenv("STA211_PROJECT_PATH")
    if env_path and (Path(env_path) / "modules").exists():
        return Path(env_path).expanduser().resolve()

    # Chemin Colab correct
    default_colab = Path("/content/drive/MyDrive/Colab Notebooks/projet_sta211_2025")
    if _in_colab() and (default_colab / "modules").exists():
        return default_colab.resolve()

    cwd = Path.cwd()
    for p in [cwd, *cwd.parents]:
        if (p / "modules").exists():
            return p.resolve()

    raise FileNotFoundError("‚ùå Impossible de localiser un dossier contenant 'modules/'.")

# ‚îÄ‚îÄ 4. D√©finition racine + PYTHONPATH
ROOT_DIR = find_project_root()
os.environ["STA211_PROJECT_PATH"] = str(ROOT_DIR)
if str(ROOT_DIR) not in sys.path:
    sys.path.insert(0, str(ROOT_DIR))
logger.info(f"üìÇ Racine projet d√©tect√©e : {ROOT_DIR}")
logger.info(f"PYTHONPATH ‚Üê {ROOT_DIR}")

# ‚îÄ‚îÄ 5. Initialisation de la configuration projet
from modules.config import cfg
cats = ['noad.', 'ad.']
LABEL_MAP = {0: "noad.", 1: "ad."} 


# ‚îÄ‚îÄ 6. Affichage des chemins configur√©s automatiquement
def display_paths(style: bool = True):
    import pandas as pd
    paths_dict = {
        "root": cfg.paths.root,
        "raw": cfg.paths.raw,
        "processed": cfg.paths.processed,
        "models": cfg.paths.models,
        "outputs": cfg.paths.outputs,
        "artifacts": cfg.paths.artifacts
    }
    rows = [{"Cl√©": k, "Chemin": str(v)} for k, v in paths_dict.items()]
    df = pd.DataFrame(rows).set_index("Cl√©")

    # V√©rification existence
    df["Existe"] = [
        "‚úÖ" if Path(v).exists() else "‚ùå"
        for v in paths_dict.values()
    ]

    from IPython.display import display
    display(df.style.set_table_styles([
        {"selector": "th", "props": [("text-align", "left")]},
        {"selector": "td", "props": [("text-align", "left")]},
    ]) if style else df)

display_paths()
logger.info("‚úÖ Initialisation compl√®te r√©ussie - Notebook 03 pr√™t !")





# %pip install imbalanced-learn --quiet
# %pip install xgboost --quiet
# %pip install shap --quiet


## 0.2 ¬∑ Chargement des biblioth√®ques ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

from IPython.display import Markdown, display

# ‚¨áÔ∏è Imports directs des biblioth√®ques n√©cessaires
try:
  # Biblioth√®ques de base
  import pandas as pd
  import numpy as np
  import matplotlib.pyplot as plt
  import matplotlib
  import seaborn as sns

  # Scikit-learn et extensions
  import sklearn
  from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
  from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
  from sklearn.linear_model import LogisticRegression
  from sklearn.svm import SVC
  from sklearn.neural_network import MLPClassifier
  from sklearn.preprocessing import StandardScaler
  from sklearn.metrics import (
      classification_report, confusion_matrix, roc_auc_score,
      precision_recall_curve, f1_score, precision_score, recall_score
  )

  # Imbalanced-learn pour le traitement du d√©s√©quilibre
  import imblearn
  from imblearn.over_sampling import BorderlineSMOTE
  from imblearn.pipeline import Pipeline as ImbPipeline

  # XGBoost
  import xgboost as xgb
  from xgboost import XGBClassifier

  # ‚úÖ SYST√àME DE STOCKAGE UNIFI√â - Plus besoin de joblib !
  from modules.utils import load_artifact, save_artifact

  # Utilitaires
  import json
  import warnings
  from tqdm import tqdm
  import scipy

  # Configuration des warnings
  warnings.filterwarnings('ignore', category=UserWarning)
  warnings.filterwarnings('ignore', category=FutureWarning)

  logger.info("üìö Biblioth√®ques import√©es avec succ√®s")

except ImportError as e:
  logger.error(f"‚ùå Erreur d'importation : {e}")
  raise

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ‚úÖ Affichage des versions principales
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def _safe_version(mod, fallback="‚Äî"):
    """Retourne mod.__version__ ou un fallback si le module est absent."""
    try:
        return mod.__version__
    except Exception:
        return fallback

def display_modeling_library_versions():
    mods = {
        "pandas"           : pd,
        "numpy"            : np,
        "scikit-learn"     : sklearn,
        "imbalanced-learn" : imblearn,
        "xgboost"          : xgb,
        "matplotlib"       : matplotlib,
        "seaborn"          : sns,
        "scipy"            : scipy,
        "tqdm"             : __import__("tqdm"),
        "ipython"          : __import__("IPython")
    }
    versions_md = "\n".join(f"- `{k}` : {_safe_version(v)}" for k, v in mods.items())
    display(Markdown(f"‚úÖ Versions des biblioth√®ques de mod√©lisation\n{versions_md}"))

display_modeling_library_versions()
logger.info("‚úÖ Chargement des biblioth√®ques termin√©")


#!pip install scikit-optimize --quiet


# Imports pour la section etudes des variables importantes
try:
    from sklearn.inspection import permutation_importance
    from sklearn.feature_selection import RFECV, SelectKBest, f_classif
    from sklearn.metrics import roc_auc_score
    from skopt import BayesSearchCV
    from skopt.space import Real, Integer
    print("‚úÖ Imports compl√©mentaires charg√©s avec succ√®s")
except ImportError as e:
    print(f"‚ö†Ô∏è Erreur d'import : {e}")
    print("Installez les d√©pendances manquantes avec:")
    print("pip install scikit-optimize")








# === CHARGEMENT MANUEL DES ARTEFACTS DU NOTEBOOK 02 ===
from modules.utils import load_artifact
import pandas as pd

print("üì¶ Chargement des artefacts du Notebook 02...")

# ‚úÖ 1. Chargement du tableau des seuils (bon r√©pertoire)
df_all_thr = pd.read_csv(cfg.paths.artifacts / "models" / "df_all_thresholds.csv")
print(f"‚úÖ M√©triques charg√©es : {len(df_all_thr)} mod√®les")

# ‚úÖ 2. R√©cup√©ration des chemins des pipelines depuis les fichiers JSON
models_dir = cfg.paths.models / "notebook2"
pipeline_paths = {}

for method in ["knn", "mice"]:
  for version in ["full", "reduced"]:
      key = f"{method}_{version}"
      json_file = f"best_{key}_pipelines.json"
      try:
          paths_dict = load_artifact(json_file, models_dir)
          pipeline_paths[key] = paths_dict
          print(f"‚úÖ Chemins {key} : {len(paths_dict)} mod√®les")
      except Exception as e:
          print(f"‚ùå Erreur {key} : {e}")

# ‚úÖ 3. Tentative de chargement des pipelines
all_optimized_pipelines = {}
total_loaded = 0

for key, paths_dict in pipeline_paths.items():
  all_optimized_pipelines[key] = {}
  for model_name, path_str in paths_dict.items():
      try:
          # Extraire le nom de fichier du chemin
          filename = Path(path_str).name
          pipeline = load_artifact(filename, models_dir)
          all_optimized_pipelines[key][model_name] = pipeline
          total_loaded += 1
      except Exception as e:
          print(f"‚ö†Ô∏è Pipeline {model_name} ({key}) non trouv√© : {e}")

print(f"\nüìä R√âSUM√â DU CHARGEMENT :")
print(f"  ‚Ä¢ Seuils : {len(df_all_thr)} ‚úÖ")
print(f"  ‚Ä¢ Pipelines : {total_loaded} ‚úÖ")
print(f"  ‚Ä¢ Configurations : {len(pipeline_paths)} ‚úÖ")

if total_loaded > 0:
  print("üöÄ Pr√™t pour le stacking !")
else:
  print("‚ö†Ô∏è Aucun pipeline charg√© - v√©rification n√©cessaire")


# Test de la nouvelle fonction load_stacking_data()
from modules.ensembles import load_stacking_data, select_champion_models

print("=" * 60)

try:
  # Chargement avec la nouvelle fonction
  splits_new, pipelines_new, metrics_df_new, features_new = load_stacking_data()

  print("\n‚úÖ CHARGEMENT R√âUSSI !")
  print(f"üìä Splits : {len(splits_new)} m√©thodes")
  print(f"üîß Pipelines : {sum(len(v) for v in pipelines_new.values())} mod√®les")
  print(f"üìà M√©triques : {len(metrics_df_new)} entr√©es")
  print(f"üîç Features : KNN({len(features_new.get('knn', []))}), MICE({len(features_new.get('mice', []))})")

  # S√©lection des 4 champions FULL
  print("\nüèÜ S√âLECTION DES 4 CHAMPIONS FULL :")
  print("=" * 50)

  champion_pipelines, champions_df = select_champion_models(
      metrics_df_new, pipelines_new, version="FULL", top_n=4
  )

  print(f"\nüìä D√âTAILS DES CHAMPIONS :")
  print(champions_df[['model', 'Imputation', 'Version', 'f1', 'precision', 'recall']].to_string(index=False))

  # V√©rification de la compatibilit√© des features
  knn_features = len(features_new['knn'])
  mice_features = len(features_new['mice'])

  print(f"\nüîç V√âRIFICATION COMPATIBILIT√â :")
  print(f"   ‚Ä¢ Features KNN : {knn_features}")
  print(f"   ‚Ä¢ Features MICE : {mice_features}")
  print(f"   ‚Ä¢ Compatible : {'‚úÖ OUI' if knn_features == mice_features == 660 else '‚ùå NON'}")

  print(f"\nüéØ CHAMPIONS PR√äTS POUR STACKING :")
  print(f"   ‚Ä¢ Nombre de mod√®les : {len(champion_pipelines)}")
  print(f"   ‚Ä¢ Mod√®les : {list(champion_pipelines.keys())}")

  # Variables pour la suite
  globals()['splits_clean'] = splits_new
  globals()['pipelines_clean'] = pipelines_new
  globals()['metrics_clean'] = metrics_df_new
  globals()['features_clean'] = features_new
  globals()['champions_full'] = champion_pipelines
  globals()['champions_df'] = champions_df

  print(f"\n‚úÖ Variables cr√©√©es pour la suite du notebook")

except Exception as e:
  print(f"‚ùå ERREUR : {e}")
  import traceback
  traceback.print_exc()


# Impl√©mentation du StackingClassifier avec les 4 champions FULL
from modules.ensembles import create_stacking_ensemble
from sklearn.model_selection import cross_val_score
from sklearn.metrics import f1_score, classification_report

print("ü•û IMPL√âMENTATION DU STACKING AVEC LES 4 CHAMPIONS")
print("=" * 60)

# Pr√©paration des donn√©es pour le stacking

X_train_knn = splits_clean['knn']['X_train']
y_train_knn = splits_clean['knn']['y_train']
X_val_knn = splits_clean['knn']['X_val']
y_val_knn = splits_clean['knn']['y_val']
X_test_knn = splits_clean['knn']['X_test']
y_test_knn = splits_clean['knn']['y_test']

X_train_mice = splits_clean['mice']['X_train']
y_train_mice = splits_clean['mice']['y_train']
X_val_mice = splits_clean['mice']['X_val']
y_val_mice = splits_clean['mice']['y_val']
X_test_mice = splits_clean['mice']['X_test']
y_test_mice = splits_clean['mice']['y_test']

print(" Donn√©es de stacking :")
print(f"   ‚Ä¢ Train KNN : {X_train_knn.shape}")
print(f"   ‚Ä¢ Validation KNN : {X_val_knn.shape}")
print(f"   ‚Ä¢ Test KNN: {X_test_knn.shape}")

print(f"   ‚Ä¢ Train MICE : {X_train_mice.shape}")
print(f"   ‚Ä¢ Validation MICE : {X_val_mice.shape}")
print(f"   ‚Ä¢ Test MICE: {X_test_mice.shape}")






from modules.modeling import run_stacking_with_refit


# Pour le mod√®le KNN
results_knn_dict = run_stacking_with_refit(
    X_train_knn, y_train_knn, X_val_knn, y_val_knn, X_test_knn, y_test_knn,
    imputation_method='knn',
    models_dir=cfg.paths.models,
    output_dir=cfg.paths.models / "notebook3" / "stacking",
    # La fonction d√©duira automatiquement la cl√© 'stacking_classifier_knn'
    # mais on peut la sp√©cifier si on prefere:
    stacking_model_key='stacking_classifier_knn'
)

# Pour le mod√®le MICE
results_mice_dict = run_stacking_with_refit(
    X_train_mice, y_train_mice, X_val_mice, y_val_mice, X_test_mice, y_test_mice,
    imputation_method='mice',
    models_dir=cfg.paths.models,
    output_dir=cfg.paths.models / "notebook3" / "stacking",
    # La fonction d√©duira automatiquement la cl√© 'stacking_classifier_mice'
    stacking_model_key='stacking_classifier_mice'
)


# 2. Acc√©der aux mod√®les entra√Æn√©s √† partir des r√©sultats
trained_stacking_knn = results_knn_dict['model']
trained_stacking_mice = results_mice_dict['model']

# 3. R√©-optimiser les seuils en utilisant les mod√®les d√©j√† entra√Æn√©s
# et obtenir le dictionnaire 'results' au format requis
from modules.modeling import optimize_stacking_thresholds_with_trained_models

print("\n R√©-optimisation des seuils pour la visualisation...")
optimization_results = optimize_stacking_thresholds_with_trained_models(
    stacking_knn=trained_stacking_knn, # Mod√®le KNN entra√Æn√©
    stacking_mice=trained_stacking_mice, # Mod√®le MICE entra√Æn√©
    X_val_knn=X_val_knn,
    y_val_knn=y_val_knn,
    X_val_mice=X_val_mice,
    y_val_mice=y_val_mice,
    verbose=True
)
print("R√©-optimisation des seuils pour la visualisation...")
optimization_results = optimize_stacking_thresholds_with_trained_models(
    stacking_knn=trained_stacking_knn, # Mod√®le KNN entra√Æn√©
    stacking_mice=trained_stacking_mice, # Mod√®le MICE entra√Æn√©
    X_val_knn=X_val_knn,
    y_val_knn=y_val_knn,
    X_val_mice=X_val_mice,
    y_val_mice=y_val_mice,
    verbose=True
)
print("R√©-optimisation termin√©e.")


from modules.modeling import analyze_model_performance

# Pour KNN
analyze_model_performance(results_knn_dict, X_test_knn, y_test_knn, "Stacking avec Refit KNN")

# Pour MICE
analyze_model_performance(results_mice_dict, X_test_mice, y_test_mice, "Stacking avec Refit MICE")


# VALIDATION FINALE DES PERFORMANCES SUR LE TEST
print("üèÜ VALIDATION FINALE - STACKING vs CHAMPION INDIVIDUEL")
print("=" * 60)

# Test des mod√®les de stacking sur le jeu de test
print("üìä PERFORMANCES SUR LE JEU DE TEST :")
print("-" * 40)

# Stacking KNN sur test
y_test_pred_stacking_knn = trained_stacking_knn.predict(X_test_knn)
y_test_proba_stacking_knn = trained_stacking_knn.predict_proba(X_test_knn)[:, 1]

# Application du seuil optimal (0.20)
y_test_pred_knn_optimized = (y_test_proba_stacking_knn >= 0.20).astype(int)
knn_f1_test = f1_score(y_test_knn, y_test_pred_knn_optimized)
knn_precision_test = precision_score(y_test_knn, y_test_pred_knn_optimized)
knn_recall_test = recall_score(y_test_knn, y_test_pred_knn_optimized)

print(f"‚úÖ STACKING KNN (seuil=0.20) :")
print(f"   F1-Score  : {knn_f1_test:.4f}")
print(f"   Pr√©cision : {knn_precision_test:.4f}")
print(f"   Rappel    : {knn_recall_test:.4f}")

# Stacking MICE sur test
y_test_pred_stacking_mice = trained_stacking_mice.predict(X_test_mice)
y_test_proba_stacking_mice = trained_stacking_mice.predict_proba(X_test_mice)[:, 1]

# Application du seuil optimal (0.26)
y_test_pred_mice_optimized = (y_test_proba_stacking_mice >= 0.26).astype(int)
mice_f1_test = f1_score(y_test_mice, y_test_pred_mice_optimized)
mice_precision_test = precision_score(y_test_mice, y_test_pred_mice_optimized)
mice_recall_test = recall_score(y_test_mice, y_test_pred_mice_optimized)

print(f"\n‚úÖ STACKING MICE (seuil=0.26) :")
print(f"   F1-Score  : {mice_f1_test:.4f}")
print(f"   Pr√©cision : {mice_precision_test:.4f}")
print(f"   Rappel    : {mice_recall_test:.4f}")

# Comparaison avec champion individuel
print(f"\nüèÜ COMPARAISON FINALE :")
print("=" * 30)
print(f"ü•á XGBoost KNN individuel : F1 = 0.9385")
print(f"ü•à Stacking MICE optimis√© : F1 = {mice_f1_test:.4f}")
print(f"ü•â Stacking KNN optimis√©  : F1 = {knn_f1_test:.4f}")

# D√©terminer le nouveau champion
best_f1 = max(0.9385, mice_f1_test, knn_f1_test)
if best_f1 == mice_f1_test and mice_f1_test > 0.9385:
  champion = "Stacking MICE"
  print(f"\nüéâ NOUVEAU CHAMPION : Stacking MICE (F1 = {mice_f1_test:.4f})")
elif best_f1 == knn_f1_test and knn_f1_test > 0.9385:
  champion = "Stacking KNN"
  print(f"\nüéâ NOUVEAU CHAMPION : Stacking KNN (F1 = {knn_f1_test:.4f})")
else:
  champion = "XGBoost KNN"
  print(f"\nüèÜ CHAMPION MAINTENU : XGBoost KNN (F1 = 0.9385)")

  # Analyser la proximit√©
  mice_diff = 0.9385 - mice_f1_test
  knn_diff = 0.9385 - knn_f1_test

  if mice_diff < 0.01:
      print(f"   Stacking MICE tr√®s proche (-{mice_diff:.4f})")
  if knn_diff < 0.01:
      print(f"   Stacking KNN tr√®s proche (-{knn_diff:.4f})")

print(f"\nüìà ANALYSE DES PERFORMANCES :")
print("-" * 35)
print(f"‚Ä¢ Objectif initial F1 > 0.92 : ‚úÖ LARGEMENT D√âPASS√â")
print(f"‚Ä¢ Stacking MICE atteint : {mice_f1_test:.4f} ({(mice_f1_test/0.92-1)*100:+.1f}%)")
print(f"‚Ä¢ Stacking KNN atteint : {knn_f1_test:.4f} ({(knn_f1_test/0.92-1)*100:+.1f}%)")
print(f"‚Ä¢ Champion XGBoost : 0.9385 (+{(0.9385/0.92-1)*100:.1f}%)")

# Recommandation finale mise √† jour
print(f"\nüí° RECOMMANDATION FINALE MISE √Ä JOUR :")
print("=" * 40)

if mice_f1_test > 0.93:
  print(f"üèÜ RECOMMANDATION : Stacking MICE")
  print(f"   ‚Ä¢ Performance exceptionnelle : F1 = {mice_f1_test:.4f}")
  print(f"   ‚Ä¢ Seuil optimal : 0.26")
  print(f"   ‚Ä¢ Combine la force de 5 mod√®les MICE")
elif knn_f1_test > 0.93:
  print(f"üèÜ RECOMMANDATION : Stacking KNN")
  print(f"   ‚Ä¢ Performance exceptionnelle : F1 = {knn_f1_test:.4f}")
  print(f"   ‚Ä¢ Seuil optimal : 0.20")
  print(f"   ‚Ä¢ Combine la force de 5 mod√®les KNN")
else:
  print(f"üèÜ RECOMMANDATION : XGBoost KNN FULL")
  print(f"   ‚Ä¢ Performance de r√©f√©rence : F1 = 0.9385")
  print(f"   ‚Ä¢ Plus simple et stable")
  print(f"   ‚Ä¢ Alternative : Stacking MICE (F1 = {mice_f1_test:.4f})")

# Sauvegarde des r√©sultats finaux
final_stacking_results = {
  'stacking_knn': {
      'f1_test': knn_f1_test,
      'precision_test': knn_precision_test,
      'recall_test': knn_recall_test,
      'optimal_threshold': 0.20,
      'model': trained_stacking_knn
  },
  'stacking_mice': {
      'f1_test': mice_f1_test,
      'precision_test': mice_precision_test,
      'recall_test': mice_recall_test,
      'optimal_threshold': 0.26,
      'model': trained_stacking_mice
  },
  'champion': champion,
  'best_f1': best_f1
}

globals()['final_stacking_results'] = final_stacking_results
print(f"\nüíæ R√©sultats finaux sauvegard√©s dans 'final_stacking_results'")
print(f"üöÄ Analyse compl√®te termin√©e !")





from modules.config import cfg
from modules.modeling import run_stacking_no_refit

MODELS_DIR_NB2  = cfg.paths.models / "notebook2"
OUTPUT_DIR      = cfg.paths.models / "notebook3" / "stacking"

results_knn_no_refit  = run_stacking_no_refit(
    X_val_knn, y_val_knn, X_test_knn, y_test_knn,
    imputation_method="knn",
    models_dir=MODELS_DIR_NB2,
    output_dir=OUTPUT_DIR
)

results_mice_no_refit = run_stacking_no_refit(
    X_val_mice, y_val_mice, X_test_mice, y_test_mice,
    imputation_method="mice",
    models_dir=MODELS_DIR_NB2,
    output_dir=OUTPUT_DIR
)

# R√©sultats de F1 sur le jeu test
if results_knn_no_refit:
    print(f"KNN¬†: F1 = {results_knn_no_refit['metrics'].get('f1_score_test'):.4f}")
if results_mice_no_refit:
    print(f"MICE : F1 = {results_mice_no_refit['metrics'].get('f1_score_test'):.4f}")






# --- 5. COMPARAISON DES MOD√àLES ---

from modules.modeling import build_comparison_table 
from pathlib import Path


# --- D√©finir les chemins des fichiers JSON de r√©sultats ---

json_paths = [
    cfg.paths.models / "notebook3" / "stacking" / "stacking_no_refit_knn_full.json",
    cfg.paths.models /"notebook3"  / "stacking" / "stacking_no_refit_mice_full.json",
    cfg.paths.models /"notebook3"  / "stacking"/ "stacking_with_refit_knn.json",
    cfg.paths.models /"notebook3" / "stacking"/ "stacking_with_refit_mice.json"
]

# --- D√©finir les d√©tails pour l'affichage dans le tableau ---
# Les cl√©s DOIVENT correspondre exactement aux noms des FICHIERS (ce qui suit le dernier '/')
details = {
    "stacking_no_refit_knn_full.json": {"Nom Affich√©": "Stacking sans refit KNN", "Type": "Complet", "Imputation": "KNN"},
    "stacking_no_refit_mice_full.json": {"Nom Affich√©": "Stacking sans refit MICE", "Type": "Complet", "Imputation": "MICE"},
    "stacking_with_refit_knn.json": {"Nom Affich√©": "Stacking avec refit KNN", "Type": "Complet", "Imputation": "KNN"}, # Nom corrig√© (enlever _full)
    "stacking_with_refit_mice.json": {"Nom Affich√©": "Stacking avec refit MICE", "Type": "Complet", "Imputation": "MICE"} # Nom corrig√© (enlever _full)
}



# --- G√©n√©reration et affichage du tableau de comparaison ---
try:
    df_comparison = build_comparison_table(json_paths, details)
    if not df_comparison.empty:
        print("\n TABLEAU DE COMPARAISON FINAL:")
        print("=" * 100) # Ajust√© pour plus de colonnes

        # --- Version avec style color√© ---
        try:
            # V√©rifier si on est dans un environnement qui supporte le HTML (comme Jupyter/Colab)
            from IPython.display import display, HTML
            import pandas as pd

            # Appliquer le style : d√©grad√© sur la colonne F1-score (test)
            # 'background_gradient' colore les cellules. cmap='Blues'/'Greens'/'viridis' sont des options.
            # subset permet de sp√©cifier les colonnes concern√©es.
            # axis=0 pour normaliser sur toute la colonne, axis=None pour normaliser sur tout le tableau.
            styled_df = df_comparison.style.background_gradient(
                cmap='Greens', # Choix du d√©grad√© de couleur (GnBu, Blues, Greens, viridis, etc.)
                subset=['F1-score (test)'], # Colonnes sur lesquelles appliquer le style
                axis=0 # Normalisation par colonne
            ).format({ # Formater les colonnes num√©riques
                'F1-score (test)': "{:.4f}",
                'Pr√©cision (test)': "{:.4f}",
                'Rappel (test)': "{:.4f}",
                'Seuil utilis√©': "{:.3f}"
            }) # On peut ajouter .set_properties(**{'text-align': 'center'}) pour centrer le texte

            display(styled_df) # Affichage plus joli et color√© dans Colab/Jupyter
            print("(üí° Le meilleur F1-score est mis en √©vidence par une couleur plus fonc√©e)")

        except ImportError:
            # Fallback si IPython.display n'est pas disponible ou √©choue
            print(df_comparison.to_string(index=False, float_format="%.4f")) # Affichage standard
            print("\n( Pour un affichage color√©, ex√©cutez ce code dans Jupyter/Colab)")

    else:
        print("‚ö†Ô∏è Le tableau de comparaison est vide.")
        # Afficher les chemins tent√©s pour aider au debug
        print("Chemins tent√©s :")
        for p in json_paths:
            print(f" - {p}")
except Exception as e:
    print(f"‚ùå Erreur lors de la g√©n√©ration du tableau de comparaison: {e}")
    import traceback
    traceback.print_exc() # Affiche la pile d'appels pour aider au debug

print("\n‚úÖ TOUTES LES √âTAPES DE STACKING SONT TERMIN√âES !")






from utils import generate_final_predictions

# Avec le mod√®le champion (GradBoost KNN Reduced)
#submission = generate_final_predictions(use_stacking=False)

# Ou avec le stacking
submission = generate_final_predictions(use_stacking=True)






