








import sys, os, logging
from pathlib import Path

# ‚îÄ‚îÄ 0. Logger clair (avec Rich si dispo)
try:
    from rich.logging import RichHandler
    logging.basicConfig(level="INFO",
                        format="%(message)s",
                        handlers=[RichHandler(rich_tracebacks=True, markup=True)],
                        force=True)
except ModuleNotFoundError:
    logging.basicConfig(level=logging.INFO,
                        format="%(asctime)s - %(levelname)s - %(message)s",
                        stream=sys.stdout,
                        force=True)
logger = logging.getLogger(__name__)

# ‚îÄ‚îÄ 1. D√©tection environnement Colab
def _in_colab() -> bool:
    try: import google.colab
    except ImportError: return False
    else: return True

# ‚îÄ‚îÄ 2. Montage Drive manuel rapide
if _in_colab():
    from google.colab import drive
    if not Path("/content/drive/MyDrive/Colab Notebooks").exists():
        logger.info("üîó Montage de Google Drive en cours‚Ä¶")
        drive.mount("/content/drive", force_remount=False)

# ‚îÄ‚îÄ 3. Localisation racine projet STA211
def find_project_root() -> Path:
    env_path = os.getenv("STA211_PROJECT_PATH")
    if env_path and (Path(env_path) / "modules").exists():
        return Path(env_path).expanduser().resolve()

    # Chemin Colab correct
    default_colab = Path("/content/drive/MyDrive/Colab Notebooks/projet_sta211_2025")
    if _in_colab() and (default_colab / "modules").exists():
        return default_colab.resolve()

    cwd = Path.cwd()
    for p in [cwd, *cwd.parents]:
        if (p / "modules").exists():
            return p.resolve()

    raise FileNotFoundError("‚ùå Impossible de localiser un dossier contenant 'modules/'.")

# ‚îÄ‚îÄ 4. D√©finition racine + PYTHONPATH
ROOT_DIR = find_project_root()
os.environ["STA211_PROJECT_PATH"] = str(ROOT_DIR)
if str(ROOT_DIR) not in sys.path:
    sys.path.insert(0, str(ROOT_DIR))
logger.info(f"üìÇ Racine projet d√©tect√©e : {ROOT_DIR}")
logger.info(f"PYTHONPATH ‚Üê {ROOT_DIR}")

# ‚îÄ‚îÄ 5. Initialisation de la configuration projet
from modules.config import cfg
cats = ['noad.', 'ad.']
LABEL_MAP = {0: "noad.", 1: "ad."} 


# ‚îÄ‚îÄ 6. Affichage des chemins configur√©s automatiquement
def display_paths(style: bool = True):
    import pandas as pd
    paths_dict = {
        "root": cfg.paths.root,
        "raw": cfg.paths.raw,
        "processed": cfg.paths.processed,
        "models": cfg.paths.models,
        "outputs": cfg.paths.outputs,
        "artifacts": cfg.paths.artifacts
    }
    rows = [{"Cl√©": k, "Chemin": str(v)} for k, v in paths_dict.items()]
    df = pd.DataFrame(rows).set_index("Cl√©")

    # V√©rification existence
    df["Existe"] = [
        "‚úÖ" if Path(v).exists() else "‚ùå"
        for v in paths_dict.values()
    ]

    from IPython.display import display
    display(df.style.set_table_styles([
        {"selector": "th", "props": [("text-align", "left")]},
        {"selector": "td", "props": [("text-align", "left")]},
    ]) if style else df)

display_paths()
logger.info("‚úÖ Initialisation compl√®te r√©ussie - Notebook 03 pr√™t !")





# %pip install imbalanced-learn --quiet
# %pip install xgboost --quiet
# %pip install shap --quiet


## 0.2 ¬∑ Chargement des biblioth√®ques ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

from IPython.display import Markdown, display

# ‚¨áÔ∏è Imports directs des biblioth√®ques n√©cessaires
try:
  # Biblioth√®ques de base
  import pandas as pd
  import numpy as np
  import matplotlib.pyplot as plt
  import matplotlib
  import seaborn as sns

  # Scikit-learn et extensions
  import sklearn
  from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
  from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
  from sklearn.linear_model import LogisticRegression
  from sklearn.svm import SVC
  from sklearn.neural_network import MLPClassifier
  from sklearn.preprocessing import StandardScaler
  from sklearn.metrics import (
      classification_report, confusion_matrix, roc_auc_score,
      precision_recall_curve, f1_score, precision_score, recall_score
  )

  # Imbalanced-learn pour le traitement du d√©s√©quilibre
  import imblearn
  from imblearn.over_sampling import BorderlineSMOTE
  from imblearn.pipeline import Pipeline as ImbPipeline

  # XGBoost
  import xgboost as xgb
  from xgboost import XGBClassifier

  # ‚úÖ SYST√àME DE STOCKAGE UNIFI√â - Plus besoin de joblib !
  from modules.utils import load_artifact, save_artifact

  # Utilitaires
  import json
  import warnings
  from tqdm import tqdm
  import scipy

  # Configuration des warnings
  warnings.filterwarnings('ignore', category=UserWarning)
  warnings.filterwarnings('ignore', category=FutureWarning)

  logger.info("üìö Biblioth√®ques import√©es avec succ√®s")

except ImportError as e:
  logger.error(f"‚ùå Erreur d'importation : {e}")
  raise

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ‚úÖ Affichage des versions principales
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def _safe_version(mod, fallback="‚Äî"):
    """Retourne mod.__version__ ou un fallback si le module est absent."""
    try:
        return mod.__version__
    except Exception:
        return fallback

def display_modeling_library_versions():
    mods = {
        "pandas"           : pd,
        "numpy"            : np,
        "scikit-learn"     : sklearn,
        "imbalanced-learn" : imblearn,
        "xgboost"          : xgb,
        "matplotlib"       : matplotlib,
        "seaborn"          : sns,
        "scipy"            : scipy,
        "tqdm"             : __import__("tqdm"),
        "ipython"          : __import__("IPython")
    }
    versions_md = "\n".join(f"- `{k}` : {_safe_version(v)}" for k, v in mods.items())
    display(Markdown(f"‚úÖ Versions des biblioth√®ques de mod√©lisation\n{versions_md}"))

display_modeling_library_versions()
logger.info("‚úÖ Chargement des biblioth√®ques termin√©")


#!pip install scikit-optimize --quiet


# Imports pour la section etudes des variables importantes
try:
    from sklearn.inspection import permutation_importance
    from sklearn.feature_selection import RFECV, SelectKBest, f_classif
    from sklearn.metrics import roc_auc_score
    from skopt import BayesSearchCV
    from skopt.space import Real, Integer
    print("‚úÖ Imports compl√©mentaires charg√©s avec succ√®s")
except ImportError as e:
    print(f"‚ö†Ô∏è Erreur d'import : {e}")
    print("Installez les d√©pendances manquantes avec:")
    print("pip install scikit-optimize")








# === CHARGEMENT MANUEL DES ARTEFACTS DU NOTEBOOK 02 ===
from modules.utils import load_artifact
import pandas as pd

print("üì¶ Chargement des artefacts du Notebook 02...")

# ‚úÖ 1. Chargement du tableau des seuils (bon r√©pertoire)
df_all_thr = pd.read_csv(cfg.paths.artifacts / "models" / "df_all_thresholds.csv")
print(f"‚úÖ M√©triques charg√©es : {len(df_all_thr)} mod√®les")

# ‚úÖ 2. R√©cup√©ration des chemins des pipelines depuis les fichiers JSON
models_dir = cfg.paths.models / "notebook2"
pipeline_paths = {}

for method in ["knn", "mice"]:
  for version in ["full", "reduced"]:
      key = f"{method}_{version}"
      json_file = f"best_{key}_pipelines.json"
      try:
          paths_dict = load_artifact(json_file, models_dir)
          pipeline_paths[key] = paths_dict
          print(f"‚úÖ Chemins {key} : {len(paths_dict)} mod√®les")
      except Exception as e:
          print(f"‚ùå Erreur {key} : {e}")

# ‚úÖ 3. Tentative de chargement des pipelines
all_optimized_pipelines = {}
total_loaded = 0

for key, paths_dict in pipeline_paths.items():
  all_optimized_pipelines[key] = {}
  for model_name, path_str in paths_dict.items():
      try:
          # Extraire le nom de fichier du chemin
          filename = Path(path_str).name
          pipeline = load_artifact(filename, models_dir)
          all_optimized_pipelines[key][model_name] = pipeline
          total_loaded += 1
      except Exception as e:
          print(f"‚ö†Ô∏è Pipeline {model_name} ({key}) non trouv√© : {e}")

print(f"\nüìä R√âSUM√â DU CHARGEMENT :")
print(f"  ‚Ä¢ Seuils : {len(df_all_thr)} ‚úÖ")
print(f"  ‚Ä¢ Pipelines : {total_loaded} ‚úÖ")
print(f"  ‚Ä¢ Configurations : {len(pipeline_paths)} ‚úÖ")

if total_loaded > 0:
  print("üöÄ Pr√™t pour le stacking !")
else:
  print("‚ö†Ô∏è Aucun pipeline charg√© - v√©rification n√©cessaire")


# === S√âLECTION DES CHAMPIONS HOMOG√àNES POUR LE STACKING ===

# S√©lectionner uniquement les champions FULL (660 features)
champions_full = df_all_thr[df_all_thr['Version'] == 'FULL'].head(4)
print("üèÜ Champions FULL seulement (donn√©es homog√®nes) :")
display(champions_full[["model", "Imputation", "Version", "f1", "threshold"]])

# ‚úÖ Validation de la compatibilit√©
print(f"\nüîç Validation de la compatibilit√© :")
champions_list = []

for _, champion in champions_full.iterrows():
  key = f"{champion['Imputation'].lower()}_{champion['Version'].lower()}"
  model_name = champion['model']

  if key in all_optimized_pipelines and model_name in all_optimized_pipelines[key]:
      pipeline = all_optimized_pipelines[key][model_name]
      champions_list.append({
          'name': f"{model_name}_{champion['Imputation']}_FULL",
          'pipeline': pipeline,
          'threshold': champion['threshold'],
          'f1_val': champion['f1'],
          'key': key,
          'model': model_name,
          'imputation': champion['Imputation']
      })
      print(f"  ‚úÖ {model_name} + {champion['Imputation']} FULL (F1={champion['f1']:.4f})")
  else:
      print(f"  ‚ùå {model_name} + {champion['Imputation']} FULL - Pipeline non trouv√©")

print(f"\nüìä √âQUIPE DE STACKING :")
print(f"  ‚Ä¢ Membres : {len(champions_list)} mod√®les")
print(f"  ‚Ä¢ Features : 660 (homog√®nes)")
print(f"  ‚Ä¢ F1 moyen : {sum(c['f1_val'] for c in champions_list) / len(champions_list):.4f}")
print(f"  ‚Ä¢ Objectif : > {max(c['f1_val'] for c in champions_list):.4f}")

# Stockage pour le stacking
stacking_champions = champions_list
print(f"\nüöÄ Champions pr√™ts pour le stacking !")



# Utilisation dans vos pipelines
# Pour les mod√®les KNN
X_train_knn = splits["knn"]["X_train"][features_knn]
X_val_knn = splits["knn"]["X_val"][features_knn]
X_test_knn = splits["knn"]["X_test"][features_knn]
y_val_knn = splits["knn"]["y_val"]
y_train_knn = splits["knn"]["y_train"]
y_test_knn = splits["knn"]["y_test"]

# Pour les mod√®les MICE
X_train_mice = splits["mice"]["X_train"][features_mice]
X_val_mice = splits["mice"]["X_val"][features_mice]
X_test_mice = splits["mice"]["X_test"][features_mice]
y_test_mice = splits["mice"]["y_test"]
y_train_mice = splits["mice"]["y_train"]
y_val_mice = splits["mice"]["y_val"]


# === IMPL√âMENTATION DU STACKING CLASSIFIER ===
from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score
import numpy as np

print(" Construction du StackingClassifier...")

# ‚úÖ 1. Pr√©paration des mod√®les de base (base learners)
base_learners = []
for champion in stacking_champions:
  estimator_name = champion['name']
  pipeline = champion['pipeline']
  base_learners.append((estimator_name, pipeline))
  print(f" {estimator_name} ajout√©")

# ‚úÖ 2. Configuration du m√©ta-mod√®le
meta_model = LogisticRegression(
  random_state=42,
  max_iter=1000,
  class_weight='balanced'  # Pour g√©rer le d√©s√©quilibre r√©siduel
)

# ‚úÖ 3. Cr√©ation du StackingClassifier
stacking_clf = StackingClassifier(
  estimators=base_learners,
  final_estimator=meta_model,
  cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),
  stack_method='predict_proba',  # Utilise les probabilit√©s (plus riche)
  n_jobs=-1,
  verbose=0
)

print(f"\nüéØ StackingClassifier configur√© :")
print(f"  ‚Ä¢ Base learners : {len(base_learners)}")
print(f"  ‚Ä¢ M√©ta-mod√®le : {type(meta_model).__name__}")
print(f"  ‚Ä¢ CV folds : 5 (stratifi√©)")
print(f"  ‚Ä¢ Stack method : predict_proba")


print(f"\nüìä Donn√©es d'entra√Ænement :")
print(f"  ‚Ä¢ Train : {X_train_stack.shape}")
print(f"  ‚Ä¢ Validation : {X_val_stack.shape}")
print(f"  ‚Ä¢ Features : {X_train_stack.shape[1]} (homog√®nes)")

# ‚úÖ 5. Entra√Ænement du StackingClassifier
print(f"\n Entra√Ænement du stacking en cours...")
print(" (Cela peut prendre quelques minutes avec 4 mod√®les + m√©ta-mod√®le)")

try:
  stacking_clf.fit(X_train_stack, y_train_stack)
  print("‚úÖ Stacking entra√Æn√© avec succ√®s !")

  # ‚úÖ 6. Pr√©dictions sur validation
  y_pred_stack = stacking_clf.predict(X_val_stack)
  y_proba_stack = stacking_clf.predict_proba(X_val_stack)[:, 1]

  # ‚úÖ 7. M√©triques initiales (seuil 0.5)
  f1_initial = f1_score(y_val_stack, y_pred_stack)
  precision_initial = precision_score(y_val_stack, y_pred_stack)
  recall_initial = recall_score(y_val_stack, y_pred_stack)
  auc_initial = roc_auc_score(y_val_stack, y_proba_stack)

  print(f"\nüìà PERFORMANCES INITIALES (seuil 0.5) :")
  print(f"  ‚Ä¢ F1-score : {f1_initial:.4f}")
  print(f"  ‚Ä¢ Precision : {precision_initial:.4f}")
  print(f"  ‚Ä¢ Recall : {recall_initial:.4f}")
  print(f"  ‚Ä¢ AUC : {auc_initial:.4f}")

  # ‚úÖ 8. Comparaison avec le champion individuel
  best_individual_f1 = max(c['f1_val'] for c in stacking_champions)
  improvement = f1_initial - best_individual_f1

  print(f"\n COMPARAISON :")
  print(f"  ‚Ä¢ Meilleur individuel : {best_individual_f1:.4f}")
  print(f"  ‚Ä¢ Stacking (seuil 0.5) : {f1_initial:.4f}")
  print(f"  ‚Ä¢ Gain initial : {improvement:+.4f}")

  if improvement > 0:
      print(" Le stacking am√©liore d√©j√† les performances !")
  else:
      print(" Optimisation du seuil n√©cessaire...")

except Exception as e:
  print(f"‚ùå Erreur lors de l'entra√Ænement : {e}")
  raise

print("\n Pr√™t pour l'optimisation du seuil !")


Print("Arret expr√®s")





from modules.modeling import run_stacking_with_refit


# Pour le mod√®le KNN
results_knn_dict = run_stacking_with_refit(
    X_train_knn, y_train_knn, X_val_knn, y_val_knn, X_test_knn, y_test_knn,
    imputation_method='knn',
    models_dir=MODELS_DIR,
    output_dir=MODELS_DIR / "notebook3" / "stacking",
    # La fonction d√©duira automatiquement la cl√© 'stacking_classifier_knn'
    # mais on peut la sp√©cifier si on prefere:
    stacking_model_key='stacking_classifier_knn'
)

# Pour le mod√®le MICE
results_mice_dict = run_stacking_with_refit(
    X_train_mice, y_train_mice, X_val_mice, y_val_mice, X_test_mice, y_test_mice,
    imputation_method='mice',
    models_dir=MODELS_DIR,
    output_dir=MODELS_DIR / "notebook3" / "stacking",
    # La fonction d√©duira automatiquement la cl√© 'stacking_classifier_mice'
    stacking_model_key='stacking_classifier_mice'
)


# 2. Acc√©der aux mod√®les entra√Æn√©s √† partir des r√©sultats
trained_stacking_knn = results_knn_dict['model']
trained_stacking_mice = results_mice_dict['model']

# 3. R√©-optimiser les seuils en utilisant les mod√®les d√©j√† entra√Æn√©s
# et obtenir le dictionnaire 'results' au format requis
from modules.modeling import optimize_stacking_thresholds_with_trained_models

print("\n R√©-optimisation des seuils pour la visualisation...")
optimization_results = optimize_stacking_thresholds_with_trained_models(
    stacking_knn=trained_stacking_knn, # Mod√®le KNN entra√Æn√©
    stacking_mice=trained_stacking_mice, # Mod√®le MICE entra√Æn√©
    X_val_knn=X_val_knn,
    y_val_knn=y_val_knn,
    X_val_mice=X_val_mice,
    y_val_mice=y_val_mice,
    verbose=True
)
print("R√©-optimisation des seuils pour la visualisation...")
optimization_results = optimize_stacking_thresholds_with_trained_models(
    stacking_knn=trained_stacking_knn, # Mod√®le KNN entra√Æn√©
    stacking_mice=trained_stacking_mice, # Mod√®le MICE entra√Æn√©
    X_val_knn=X_val_knn,
    y_val_knn=y_val_knn,
    X_val_mice=X_val_mice,
    y_val_mice=y_val_mice,
    verbose=True
)
print("R√©-optimisation termin√©e.")


from modules.modeling import analyze_model_performance

# Pour KNN
analyze_model_performance(results_knn_dict, X_test_knn, y_test_knn, "Stacking avec Refit KNN")

# Pour MICE
analyze_model_performance(results_mice_dict, X_test_mice, y_test_mice, "Stacking avec Refit MICE")





# --- 1. STACKING SANS REFIT (Utilisation de la fonction refactoris√©e) ---
print("\n" + "="*80)
print("D√âMARRAGE DU STACKING SANS REFIT")
print("="*80)

from modules.modeling import run_stacking_no_refit
# Utiliser le bon r√©pertoire pour les pipelines
MODELS_DIR_NB2 = str(cfg.paths.OUTPUTS_DIR / "modeling" / "notebook2")

# Stacking sans refit avec le bon chemin
print("STACKING SANS REFIT - KNN")
print("=" * 80)
results_knn_no_refit = run_stacking_no_refit(
    X_val_knn, y_val_knn, X_test_knn, y_test_knn,
    imputation_method="knn",
    models_dir=MODELS_DIR_NB2  # Utiliser le bon chemin
)

print("\nSTACKING SANS REFIT - MICE") 
print("=" * 80)
results_mice_no_refit = run_stacking_no_refit(
    X_val_mice, y_val_mice, X_test_mice, y_test_mice,
    imputation_method="mice", 
    models_dir=MODELS_DIR_NB2  # Utiliser le bon chemin
)





# --- 5. COMPARAISON DES MOD√àLES ---

from modules.modeling import build_comparison_table 
from pathlib import Path


# --- D√©finir les chemins des fichiers JSON de r√©sultats ---
# Utilisez les chemins r√©els o√π vos fichiers sont sauvegard√©s
json_paths = [
    MODELS_DIR / "notebook3" / "stacking" / "stacking_no_refit_knn_full.json",
    MODELS_DIR /"notebook3"  / "stacking" / "stacking_no_refit_mice_full.json",
    MODELS_DIR /"notebook3"  / "stacking"/ "stacking_with_refit_knn.json",
    MODELS_DIR /"notebook3" / "stacking"/ "stacking_with_refit_mice.json"
]

# --- D√©finir les d√©tails pour l'affichage dans le tableau ---
# Les cl√©s DOIVENT correspondre exactement aux noms des FICHIERS (ce qui suit le dernier '/')
details = {
    "stacking_no_refit_knn_full.json": {"Nom Affich√©": "Stacking sans refit KNN", "Type": "Complet", "Imputation": "KNN"},
    "stacking_no_refit_mice_full.json": {"Nom Affich√©": "Stacking sans refit MICE", "Type": "Complet", "Imputation": "MICE"},
    "stacking_with_refit_knn.json": {"Nom Affich√©": "Stacking avec refit KNN", "Type": "Complet", "Imputation": "KNN"}, # Nom corrig√© (enlever _full)
    "stacking_with_refit_mice.json": {"Nom Affich√©": "Stacking avec refit MICE", "Type": "Complet", "Imputation": "MICE"} # Nom corrig√© (enlever _full)
}



# --- G√©n√©reration et affichage du tableau de comparaison ---
try:
    df_comparison = build_comparison_table(json_paths, details)
    if not df_comparison.empty:
        print("\n TABLEAU DE COMPARAISON FINAL:")
        print("=" * 100) # Ajust√© pour plus de colonnes

        # --- Version avec style color√© ---
        try:
            # V√©rifier si on est dans un environnement qui supporte le HTML (comme Jupyter/Colab)
            from IPython.display import display, HTML
            import pandas as pd

            # Appliquer le style : d√©grad√© sur la colonne F1-score (test)
            # 'background_gradient' colore les cellules. cmap='Blues'/'Greens'/'viridis' sont des options.
            # subset permet de sp√©cifier les colonnes concern√©es.
            # axis=0 pour normaliser sur toute la colonne, axis=None pour normaliser sur tout le tableau.
            styled_df = df_comparison.style.background_gradient(
                cmap='Greens', # Choix du d√©grad√© de couleur (GnBu, Blues, Greens, viridis, etc.)
                subset=['F1-score (test)'], # Colonnes sur lesquelles appliquer le style
                axis=0 # Normalisation par colonne
            ).format({ # Formater les colonnes num√©riques
                'F1-score (test)': "{:.4f}",
                'Pr√©cision (test)': "{:.4f}",
                'Rappel (test)': "{:.4f}",
                'Seuil utilis√©': "{:.3f}"
            }) # On peut ajouter .set_properties(**{'text-align': 'center'}) pour centrer le texte

            display(styled_df) # Affichage plus joli et color√© dans Colab/Jupyter
            print("(üí° Le meilleur F1-score est mis en √©vidence par une couleur plus fonc√©e)")

        except ImportError:
            # Fallback si IPython.display n'est pas disponible ou √©choue
            print(df_comparison.to_string(index=False, float_format="%.4f")) # Affichage standard
            print("\n( Pour un affichage color√©, ex√©cutez ce code dans Jupyter/Colab)")

    else:
        print("‚ö†Ô∏è Le tableau de comparaison est vide.")
        # Afficher les chemins tent√©s pour aider au debug
        print("Chemins tent√©s :")
        for p in json_paths:
            print(f" - {p}")
except Exception as e:
    print(f"‚ùå Erreur lors de la g√©n√©ration du tableau de comparaison: {e}")
    import traceback
    traceback.print_exc() # Affiche la pile d'appels pour aider au debug

print("\n‚úÖ TOUTES LES √âTAPES DE STACKING SONT TERMIN√âES !")






# Imports et Chargement Initial
from sklearn.pipeline import Pipeline as SklearnPipeline
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import RFECV
from sklearn.model_selection import StratifiedKFold
from sklearn.ensemble import GradientBoostingClassifier

# Chargement du pipeline GradientBoosting optimis√© MICE
pipeline_gradboost_mice = all_optimized_pipelines["gradboost_mice_full"]

# Suppression de l'√©tape SMOTE et reconstruction du pr√©processeur
steps = [s for s in pipeline_gradboost_mice.steps[:-1] if "smote" not in s[0].lower()]
preprocessor_mice = SklearnPipeline(steps=steps)

# Pr√©traitement des donn√©es
X_train_mice_processed = preprocessor_mice.fit_transform(X_train_mice)
X_val_mice_processed = preprocessor_mice.transform(X_val_mice)
X_test_mice_processed = preprocessor_mice.transform(X_test_mice)

# Extraction du GradientBoosting optimis√©
gradboost_estimator = pipeline_gradboost_mice.named_steps["clf"]

# Import et analyse des features
from modules.modeling import analyze_feature_importance

print("ANALYSE DE L'IMPORTANCE DES FEATURES")
print("="*50)
print("Mod√®le : GradientBoosting MICE FULL (F1=0.9313)")
print("Version : FULL, Seuil optimal : 0.491")

analyze_feature_importance(
    model=gradboost_estimator,
    X_train=X_train_mice_processed,
    y_train=y_train_mice,
    X_eval=X_val_mice_processed,
    y_eval=y_val_mice,
    feature_names=feature_cols,
    method='all',
    cv_folds=5,
    model_name="GradientBoosting_MICE_FULL"
)


def get_feature_names_after_preprocessing(preprocessor, X_original):
    """
    Tente d'obtenir les noms de features apr√®s transformation par un pipeline.
    """
    try:
        # Si le preprocessor et tous ses steps supportent get_feature_names_out
        return preprocessor.get_feature_names_out(X_original.columns).tolist()
    except Exception as e:
        # Si √©chec, cr√©er des noms g√©n√©riques
        # V√©rifier le nombre de features apr√®s transformation
        X_transformed_sample = preprocessor.transform(X_original.head(1)) # Un √©chantillon
        n_features_out = X_transformed_sample.shape[1]
        print(" Impossible d'obtenir les noms des features via get_feature_names_out. "
              f"G√©n√©ration de noms g√©n√©riques pour {n_features_out} features.")
        return [f"feature_processed_{i}" for i in range(n_features_out)]



print("\n" + "="*80)
print(" CHARGEMENT DU MOD√àLE GRADIENT BOOSTING COMPLET")
print("="*80)

import joblib
from pathlib import Path

# 1. Charger le pipeline Gradient Boosting complet
pipeline_gradboost_mice_full_path = MODELS_DIR / "notebook2" / "mice" / "pipeline_gradboost_mice_full.joblib"

print(f"üìÅ Chargement depuis : {pipeline_gradboost_mice_full_path}")

if pipeline_gradboost_mice_full_path.exists():
    pipeline_gradboost_mice_full = joblib.load(pipeline_gradboost_mice_full_path)
    print("‚úÖ Pipeline Gradient Boosting MICE complet charg√© avec succ√®s")
else:
    print(f"‚ùå Fichier non trouv√© : {pipeline_gradboost_mice_full_path}")
    raise FileNotFoundError(f"Le fichier {pipeline_gradboost_mice_full_path} n'existe pas")

# 2. Extraire le mod√®le et le pr√©processeur (correction des noms d'√©tapes)
gradboost_estimator_full = pipeline_gradboost_mice_full.named_steps["clf"]
scaler_full = pipeline_gradboost_mice_full.named_steps["scale"]

print(f"üìä Informations du mod√®le :")
print(f"   ‚Ä¢ Type de mod√®le : {type(gradboost_estimator_full).__name__}")
print(f"   ‚Ä¢ Nombre de features attendues : {gradboost_estimator_full.n_features_in_}")
print(f"   ‚Ä¢ Nombre d'estimateurs : {getattr(gradboost_estimator_full, 'n_estimators', 'N/A')}")

# 3. Utiliser les donn√©es MICE originales
X_train_mice_original = splits["mice"]["X_train"][features_mice]
X_test_mice_original = splits["mice"]["X_test"][features_mice]
y_train_mice_original = splits["mice"]["y_train"]
y_test_mice_original = splits["mice"]["y_test"]

print(f"üìä Dimensions des donn√©es originales :")
print(f"   ‚Ä¢ X_train_original : {X_train_mice_original.shape}")
print(f"   ‚Ä¢ X_test_original : {X_test_mice_original.shape}")

# 4. Cr√©er un pr√©processeur sans SMOTE (pour l'analyse)
from sklearn.pipeline import Pipeline as SklearnPipeline
preprocessor_without_smote = SklearnPipeline([
    ('scale', scaler_full)
])

# 5. Appliquer le pr√©processeur (sans SMOTE pour l'analyse)
print(f"\n Application du pr√©processeur (sans SMOTE)...")
X_train_mice_transformed = preprocessor_without_smote.fit_transform(X_train_mice_original)
X_test_mice_transformed = preprocessor_without_smote.transform(X_test_mice_original)

print(f"üìä Dimensions apr√®s transformation :")
print(f"   ‚Ä¢ X_train_transformed : {X_train_mice_transformed.shape}")
print(f"   ‚Ä¢ X_test_transformed : {X_test_mice_transformed.shape}")

# 6. Obtenir les noms de features apr√®s transformation
try:
    feature_names_transformed = preprocessor_without_smote.get_feature_names_out()
    print(f"‚úÖ Noms de features obtenus : {len(feature_names_transformed)} features")
except Exception as e:
    print(f"‚ö†Ô∏è Impossible d'obtenir les noms de features : {e}")
    feature_names_transformed = [f"feature_{i}" for i in range(X_train_mice_transformed.shape[1])]
    print(f" Noms g√©n√©riques cr√©√©s : {len(feature_names_transformed)} features")

# 7. V√©rifier la coh√©rence des dimensions
if X_train_mice_transformed.shape[1] == gradboost_estimator_full.n_features_in_:
    print("‚úÖ Dimensions coh√©rentes entre le mod√®le et les donn√©es transform√©es")
else:
    print(f"‚ùå Incoh√©rence de dimensions :")
    print(f"   ‚Ä¢ Mod√®le attend : {gradboost_estimator_full.n_features_in_} features")
    print(f"   ‚Ä¢ Donn√©es transform√©es : {X_train_mice_transformed.shape[1]} features")
    raise ValueError("Dimensions incompatibles entre le mod√®le et les donn√©es")

# 8. Utiliser la version debug pour l'analyse
print(f"\nüîç D√âMARRAGE DE L'ANALYSE AVEC LE MOD√àLE COMPLET")
print("="*60)

from modules.modeling import analyze_feature_importance

results_gradboost_analysis_full = analyze_feature_importance(
    model=gradboost_estimator_full,
    X_train=X_train_mice_transformed,
    y_train=y_train_mice_original,
    X_eval=X_test_mice_transformed,
    y_eval=y_test_mice_original,
    feature_names=feature_names_transformed,
    method='all',
    cv_folds=10,
    n_repeats_perm=20,
    output_dir=OUTPUTS_DIR / "features_selection" / "gradboost_mice",
    model_name="GradBoost_MICE_Full_Complete",
    save_results=True
)

# 9. Cr√©er les graphiques avec le mod√®le complet
if results_gradboost_analysis_full is not None:
    print("\n" + "="*80)
    print("üìä CR√âATION DES GRAPHIQUES AVEC LE MOD√àLE COMPLET")
    print("="*80)
    
    from modules.modeling import (
        plot_rfecv_evolution, 
        plot_simple_rfecv_evolution,
        plot_feature_importance_comparison, 
        create_feature_selection_summary
    )
    
    # Graphique d'√©volution du score en fonction du nombre de variables
    print("\nüéØ Graphique d'√©volution RFECV (version simple) :")
    fig_simple = plot_simple_rfecv_evolution(
        results_dict=results_gradboost_analysis_full,
        model_name="GradBoost MICE Complet",
        save_path=OUTPUTS_DIR / "features_selection" / "gradboost_mice" / "rfecv_evolution_simple_full.png",
        figsize=(12, 8)
    )
    
    # Graphique d√©taill√© avec √©cart-type
    print("\nüìä Graphique d'√©volution RFECV (version d√©taill√©e) :")
    fig_detailed = plot_rfecv_evolution(
        results_dict=results_gradboost_analysis_full,
        model_name="GradBoost MICE Complet",
        save_path=OUTPUTS_DIR / "features_selection" / "gradboost_mice" / "rfecv_evolution_detailed_full.png",
        figsize=(14, 10)
    )
    
    # Graphique comparatif complet
    print("\nüìà Graphique comparatif complet :")
    fig_comparison = plot_feature_importance_comparison(
        results_dict=results_gradboost_analysis_full,
        model_name="GradBoost MICE Complet",
        save_path=OUTPUTS_DIR / "features_selection" / "gradboost_mice" / "feature_importance_comparison_full.png",
        figsize=(14, 10)
    )
    
    # R√©sum√© textuel d√©taill√©
    print("\n R√©sum√© d√©taill√© de l'analyse :")
    create_feature_selection_summary(
        results_dict=results_gradboost_analysis_full,
        model_name="GradBoost MICE Complet"
    )
    
    print("\n‚úÖ Graphiques cr√©√©s et sauvegard√©s avec succ√®s !")
    print(" Fichiers sauvegard√©s dans : outputs/features_selection/gradboost_mice/")
    
else:
    print("‚ùå Impossible de cr√©er les graphiques : r√©sultats d'analyse non disponibles")

print("\n" + "="*80)
print("üéâ ANALYSE TERMIN√âE AVEC LE MOD√àLE COMPLET")
print("="*80)


# =============================================================================
# GRAPHIQUE : √âVOLUTION DU SCORE EN FONCTION DU NOMBRE DE VARIABLES
# =============================================================================

if results_gradboost_analysis_full is not None:
    print("\n" + "="*80)
    print("üìä CR√âATION DES GRAPHIQUES D'ANALYSE DES FEATURES")
    print("="*80)
    
    # Import du module de visualisation
    from modules.visualization import (
        plot_rfecv_evolution, 
        plot_simple_rfecv_evolution,
        plot_feature_importance_comparison, 
        create_feature_selection_summary
    )
    
    try:
        # 1. Graphique simple et clair : √âvolution du score vs nombre de features
        print("\nüéØ Graphique d'√©volution RFECV (version simple) :")
        fig_simple = plot_simple_rfecv_evolution(
            results_dict=results_gradboost_analysis_full,
            model_name="GradBoost MICE Complet",
            save_path=OUTPUTS_DIR / "features_selection" / "gradboost_mice" / "rfecv_evolution_simple.png",
            figsize=(14, 8)
        )
        print("   ‚úÖ Graphique simple cr√©√© avec succ√®s")
        
        # 2. Graphique d√©taill√© avec √©cart-type
        print("\nüìä Graphique d'√©volution RFECV (version d√©taill√©e) :")
        fig_detailed = plot_rfecv_evolution(
            results_dict=results_gradboost_analysis_full,
            model_name="GradBoost MICE Complet",
            save_path=OUTPUTS_DIR / "features_selection" / "gradboost_mice" / "rfecv_evolution_detailed.png",
            figsize=(14, 10)
        )
        print("   ‚úÖ Graphique d√©taill√© cr√©√© avec succ√®s")
        
        # 3. Graphique comparatif complet (avec gestion des erreurs)
        print("\nüìà Graphique comparatif complet :")
        fig_comparison = plot_feature_importance_comparison(
            results_dict=results_gradboost_analysis_full,
            model_name="GradBoost MICE Complet",
            save_path=OUTPUTS_DIR / "features_selection" / "gradboost_mice" / "feature_importance_comparison.png",
            figsize=(16, 12)
        )
        print("   ‚úÖ Graphique comparatif cr√©√© avec succ√®s")
        
        # 4. R√©sum√© textuel d√©taill√©
        print("\n R√©sum√© d√©taill√© de l'analyse :")
        create_feature_selection_summary(
            results_dict=results_gradboost_analysis_full,
            model_name="GradBoost MICE Complet"
        )
        
        print("\n" + "="*80)
        print("‚úÖ TOUS LES GRAPHIQUES ONT √âT√â CR√â√âS AVEC SUCC√àS !")
        print("="*80)
        print(" Fichiers sauvegard√©s dans : outputs/features_selection/gradboost_mice/")
        print("   ‚Ä¢ rfecv_evolution_simple.png")
        print("   ‚Ä¢ rfecv_evolution_detailed.png") 
        print("   ‚Ä¢ feature_importance_comparison.png")
        print("="*80)
        
    except Exception as e:
        print(f"\n‚ùå Erreur lors de la cr√©ation des graphiques : {e}")
        print("üîç Tentative de cr√©ation avec des param√®tres simplifi√©s...")
        
        try:
            # Version simplifi√©e en cas d'erreur
            print("\nüéØ Cr√©ation d'un graphique simple de secours :")
            fig_simple = plot_simple_rfecv_evolution(
                results_dict=results_gradboost_analysis_full,
                model_name="GradBoost MICE Complet",
                save_path=OUTPUTS_DIR / "features_selection" / "gradboost_mice" / "rfecv_evolution_simple_backup.png",
                figsize=(10, 6)
            )
            print("   ‚úÖ Graphique de secours cr√©√© avec succ√®s")
            
        except Exception as e2:
            print(f"‚ùå Impossible de cr√©er m√™me le graphique de secours : {e2}")
            print("üìä Affichage des donn√©es brutes disponibles :")
            print(f"   ‚Ä¢ M√©thodes appliqu√©es : {results_gradboost_analysis_full.get('methods_applied', [])}")
            if 'rfecv' in results_gradboost_analysis_full:
                rfecv_data = results_gradboost_analysis_full['rfecv']
                print(f"   ‚Ä¢ Features optimales RFECV : {rfecv_data.get('n_features_optimal', 'N/A')}")
                print(f"   ‚Ä¢ Meilleur score RFECV : {rfecv_data.get('best_score', 'N/A')}")
    
else:
    print("\n" + "="*80)
    print("‚ùå IMPOSSIBLE DE CR√âER LES GRAPHIQUES")
    print("="*80)
    print("üîç Raisons possibles :")
    print("   ‚Ä¢ L'analyse n'a pas √©t√© ex√©cut√©e correctement")
    print("   ‚Ä¢ La variable 'results_gradboost_analysis_full' est None")
    print("   ‚Ä¢ Erreur lors de l'analyse des features")
    print("="*80)
    print("üí° V√©rifiez que la cellule d'analyse pr√©c√©dente s'est bien termin√©e")
    print("   et que la variable 'results_gradboost_analysis_full' existe.")
    print("="*80)


# Extraction des r√©sultats pour la personnalisation du markdown
if results_gradboost_analysis_full and 'rfecv' in results_gradboost_analysis_full:
    rfecv_data = results_gradboost_analysis_full['rfecv']
    n_optimal = rfecv_data.get('n_features_optimal', 'N/A')
    best_score = rfecv_data.get('best_score', 'N/A')
    print(f"Nombre optimal de variables : {n_optimal}")
    print(f"Meilleur score RFECV : {best_score}")








from utils import generate_final_predictions

# Avec le mod√®le champion (GradBoost KNN Reduced)
#submission = generate_final_predictions(use_stacking=False)

# Ou avec le stacking
submission = generate_final_predictions(use_stacking=True)






