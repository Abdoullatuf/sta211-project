# modules/prediction.py
"""
Module unifi√© pour la g√©n√©ration des pr√©dictions finales
Projet STA211 - Classification de publicit√©s
Version avec vrais mod√®les uniquement
"""

import pandas as pd
import numpy as np
import joblib
import json
import logging
from pathlib import Path
from typing import Tuple, Optional, Union

# Configuration du logger
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class PredictionPipeline:
    """Pipeline complet pour g√©n√©rer les pr√©dictions finales avec les vrais mod√®les"""
    
    def __init__(self, base_dir: Union[str, Path] = "."):
        """
        Initialise le pipeline avec les chemins du projet.
        """
        self.base_dir = Path(base_dir)
        self.models_dir = self.base_dir / "models"
        self.outputs_dir = self.base_dir / "outputs"
        self.data_dir = self.base_dir / "data"
        
        logger.info(f"Pipeline initialis√© avec base_dir: {self.base_dir}")
    
    def load_and_preprocess_test_data(self):
        """
        Charge et pr√©traite les donn√©es de test exactement comme dans les notebooks.
        """
        logger.info("Chargement et pr√©traitement des donn√©es de test...")
        
        # Charger le fichier CSV
        test_path = self.data_dir / "raw" / "data_test.csv"
        logger.info(f"Chargement des donn√©es depuis : {test_path}")
        
        # Lire d'abord pour voir la structure
        df_test = pd.read_csv(test_path)
        logger.info(f"Donn√©es charg√©es : {df_test.shape[0]} lignes, {df_test.shape[1]} colonnes")
        logger.info(f"Colonnes d√©tect√©es : {list(df_test.columns)}")
        logger.info(f"Premi√®res valeurs de la premi√®re colonne : {df_test.iloc[0:3, 0].tolist()}")
        
        # Si une seule colonne d√©tect√©e, essayer d'autres m√©thodes de parsing
        if df_test.shape[1] == 1:
            logger.warning("Une seule colonne d√©tect√©e, tentative de parsing alternatif...")
            
            # Essayer avec diff√©rents s√©parateurs
            for sep in [',', ';', '\t', ' ']:
                try:
                    df_alt = pd.read_csv(test_path, sep=sep)
                    if df_alt.shape[1] > 1:
                        logger.info(f"Parsing r√©ussi avec s√©parateur '{sep}': {df_alt.shape[1]} colonnes")
                        df_test = df_alt
                        break
                except:
                    continue
            
            # Si toujours une seule colonne, essayer de split la premi√®re colonne
            if df_test.shape[1] == 1:
                first_col_name = df_test.columns[0]
                sample_value = str(df_test.iloc[0, 0])
                logger.info(f"Tentative de split sur la premi√®re colonne. Valeur exemple: {sample_value}")
                
                # D√©tecter le pattern de s√©paration
                for sep in ['\t', ',', ';', ' ']:
                    if sep in sample_value:
                        logger.info(f"S√©parateur '{sep}' d√©tect√© dans les donn√©es")
                        # Split et cr√©er nouvelles colonnes
                        split_data = df_test[first_col_name].str.split(sep, expand=True)
                        # G√©n√©rer noms de colonnes
                        split_data.columns = [f'X{i+1}' for i in range(split_data.shape[1])]
                        df_test = split_data
                        logger.info(f"Donn√©es split√©es en {df_test.shape[1]} colonnes: {list(df_test.columns)}")
                        break
        
        logger.info(f"Structure finale apr√®s parsing : {df_test.shape[0]} lignes, {df_test.shape[1]} colonnes")
        logger.info(f"Colonnes finales : {list(df_test.columns)}")
        
        # Convertir toutes les colonnes (sauf la premi√®re qui pourrait √™tre l'ID) en num√©rique
        for col in df_test.columns:
            if col not in ['id']:  # Garder les IDs comme strings
                try:
                    df_test[col] = pd.to_numeric(df_test[col], errors='coerce')
                except Exception as e:
                    logger.warning(f"Impossible de convertir la colonne {col} en num√©rique: {e}")
        
        # V√©rifier les conversions
        numeric_cols = df_test.select_dtypes(include=[np.number]).columns
        logger.info(f"Colonnes num√©riques converties : {len(numeric_cols)}")
        
        # V√©rifier s'il y a des NaN apr√®s conversion (sauf pour les valeurs manquantes l√©gitimes)
        problematic_cols = []
        for col in df_test.columns:
            if col not in ['id'] and df_test[col].isna().any():
                na_count = df_test[col].isna().sum()
                if na_count < len(df_test) * 0.9:  # Si moins de 90% de NaN, c'est un probl√®me de conversion
                    problematic_cols.append(f"{col}: {na_count} NaN")
        
        if problematic_cols:
            logger.warning(f"Colonnes avec NaN apr√®s conversion : {problematic_cols[:5]}")  # Limite √† 5 pour le log
        
        # S√©parer features et IDs
        if 'id' in df_test.columns:
            ids = df_test['id']
            features = df_test.drop(columns=['id'])
        else:
            ids = pd.Series(range(len(df_test)))
            features = df_test
        
        return features, ids
    
    def apply_notebook1_preprocessing(self, features: pd.DataFrame, imputation_method: str = "knn"):
        """
        Applique le pr√©traitement exact du notebook 1.
        """
        logger.info(f"Application du pr√©traitement notebook 1 avec {imputation_method.upper()}...")
        
        df = features.copy()
        
        # Validation et conversion des types de donn√©es
        logger.info("Validation des types de donn√©es avant preprocessing...")
        for col in df.columns:
            if not pd.api.types.is_numeric_dtype(df[col]):
                logger.warning(f"Colonne {col} n'est pas num√©rique, conversion...")
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        logger.info(f"Types apr√®s validation : {dict(df.dtypes)}")
        
        # D√©finir les chemins selon la m√©thode d'imputation
        if imputation_method == "knn":
            base_path = self.outputs_dir / "modeling" / "notebook1" / "knn"
        else:
            base_path = self.outputs_dir / "modeling" / "notebook1" / "mice"
        
        # 1. Imputation X4 avec m√©diane
        median_path = base_path / "median_imputer_X4.pkl"
        if median_path.exists():
            median_value = joblib.load(median_path)
            # S'assurer que median_value est num√©rique
            try:
                median_value = float(median_value)
                # S'assurer que X4 est num√©rique
                if not pd.api.types.is_numeric_dtype(df['X4']):
                    df['X4'] = pd.to_numeric(df['X4'], errors='coerce')
                df['X4'] = df['X4'].fillna(median_value)
                logger.info(f"X4 imput√© avec m√©diane : {median_value}")
            except (ValueError, TypeError) as e:
                logger.warning(f"Erreur lors de l'imputation de X4: {e}, ignor√©")
        
        # 2. Imputation des variables continues X1, X2, X3
        continuous_cols = ['X1', 'X2', 'X3']
        if imputation_method == "knn":
            imputer_path = base_path / "imputer_knn_k7.pkl"
        else:
            imputer_path = base_path / "imputer_mice_custom.pkl"
        
        if imputer_path.exists():
            imputer = joblib.load(imputer_path)
            df[continuous_cols] = imputer.transform(df[continuous_cols])
            logger.info(f"Variables continues imput√©es avec {imputation_method.upper()}")
        
        # 3. Transformations Yeo-Johnson et Box-Cox
        transformers_dir = base_path / f"{imputation_method}_transformers"
        
        # Yeo-Johnson pour X1 et X2
        yj_path = transformers_dir / "yeo_johnson_transformer.pkl"
        if yj_path.exists():
            yj_transformer = joblib.load(yj_path)
            df[['X1', 'X2']] = yj_transformer.transform(df[['X1', 'X2']])
            df.rename(columns={'X1': 'X1_transformed', 'X2': 'X2_transformed'}, inplace=True)
        
        # Box-Cox pour X3
        bc_path = transformers_dir / "box_cox_transformer.pkl"
        if bc_path.exists():
            bc_transformer = joblib.load(bc_path)
            # Assurer que X3 > 0 pour Box-Cox
            df['X3'] = df['X3'].clip(lower=1e-6)
            df[['X3']] = bc_transformer.transform(df[['X3']])
            df.rename(columns={'X3': 'X3_transformed'}, inplace=True)
        
        # 4. Capping des outliers
        capping_path = base_path / f"capping_params_{imputation_method}.pkl"
        if capping_path.exists():
            capping_params = joblib.load(capping_path)
            for col in ['X1_transformed', 'X2_transformed', 'X3_transformed']:
                if col in capping_params and col in df.columns:
                    lower, upper = capping_params[col]
                    # S'assurer que les valeurs de capping sont num√©riques
                    try:
                        # Ignorer les valeurs textuelles comme 'lower_bound', 'upper_bound'
                        if isinstance(lower, str) and not lower.replace('.', '').replace('-', '').isdigit():
                            lower = None
                        if isinstance(upper, str) and not upper.replace('.', '').replace('-', '').isdigit():
                            upper = None
                            
                        lower = float(lower) if lower is not None else None
                        upper = float(upper) if upper is not None else None
                        
                        # Appliquer seulement si on a au moins une valeur valide
                        if lower is not None or upper is not None:
                            # V√©rifier que la colonne est bien num√©rique
                            if not pd.api.types.is_numeric_dtype(df[col]):
                                df[col] = pd.to_numeric(df[col], errors='coerce')
                            df[col] = df[col].clip(lower=lower, upper=upper)
                            logger.info(f"Capping appliqu√© sur {col}: [{lower}, {upper}]")
                        else:
                            logger.warning(f"Pas de valeurs de capping valides pour {col}, ignor√©")
                    except (ValueError, TypeError) as e:
                        logger.warning(f"Erreur lors du capping de {col}: {e}, ignor√©")
                        continue
            logger.info("Capping des outliers appliqu√©")
        
        # 5. Features polynomiales
        poly_path = base_path / f"poly_transformer_{imputation_method}_no_outliers.pkl"
        if poly_path.exists():
            poly_transformer = joblib.load(poly_path)
            transformed_cols = ['X1_transformed', 'X2_transformed', 'X3_transformed']
            if all(col in df.columns for col in transformed_cols):
                poly_features = poly_transformer.transform(df[transformed_cols])
                poly_names = poly_transformer.get_feature_names_out(transformed_cols)
                
                for i, name in enumerate(poly_names):
                    df[name] = poly_features[:, i]
                
                logger.info(f"Features polynomiales ajout√©es : {len(poly_names)} colonnes")
        
        # 6. Supprimer les colonnes corr√©l√©es
        cols_to_drop_path = base_path / "cols_to_drop_corr.pkl"
        if cols_to_drop_path.exists():
            cols_to_drop = joblib.load(cols_to_drop_path)
            cols_to_drop = [col for col in cols_to_drop if col in df.columns]
            if cols_to_drop:
                df = df.drop(columns=cols_to_drop)
                logger.info(f"Colonnes corr√©l√©es supprim√©es : {len(cols_to_drop)}")
        
        return df
    
    def generate_predictions_with_best_model(self):
        """
        G√©n√®re les pr√©dictions avec le meilleur mod√®le (GradBoost KNN Reduced).
        """
        logger.info("="*80)
        logger.info("G√âN√âRATION DES PR√âDICTIONS AVEC LE MOD√àLE CHAMPION")
        logger.info("="*80)
        
        # 1. Charger et pr√©traiter les donn√©es
        features, ids = self.load_and_preprocess_test_data()
        X_processed = self.apply_notebook1_preprocessing(features, imputation_method="knn")
        
        # 2. Charger le mod√®le champion et ses param√®tres
        logger.info("Chargement du mod√®le champion : GradBoost KNN Reduced")
        
        # Pipeline du mod√®le
        model_path = self.models_dir / "best_gradboost_knn_reduced.joblib"
        if not model_path.exists():
            # Essayer un autre chemin
            model_path = self.models_dir / "pipeline_gradboost_knn_reduced.joblib"
        
        if not model_path.exists():
            raise FileNotFoundError(f"Mod√®le non trouv√© : {model_path}")
        
        model = joblib.load(model_path)
        logger.info(f"Mod√®le charg√© depuis : {model_path}")
        
        # Seuil optimal
        threshold_path = self.outputs_dir / "modeling" / "thresholds" / "optimized_thresholds_knn_reduced.json"
        if threshold_path.exists():
            with open(threshold_path, 'r') as f:
                thresholds = json.load(f)
                optimal_threshold = thresholds.get('GradBoost', {}).get('threshold', 0.285)
        else:
            optimal_threshold = 0.285  # Valeur du champion selon vos r√©sultats
        
        logger.info(f"Seuil optimal : {optimal_threshold}")
        
        # 3. S√©lection des features si mod√®le reduced
        selected_features_path = self.models_dir / "knn" / "reduced" / "selected_columns_knn.pkl"
        if selected_features_path.exists():
            selected_columns = joblib.load(selected_features_path)
            # Garder seulement les colonnes qui existent
            selected_columns = [col for col in selected_columns if col in X_processed.columns]
            X_final = X_processed[selected_columns]
            logger.info(f"Features s√©lectionn√©es : {len(selected_columns)} colonnes")
        else:
            X_final = X_processed
        
        # 4. G√©n√©rer les pr√©dictions
        logger.info("G√©n√©ration des pr√©dictions...")
        y_proba = model.predict_proba(X_final)[:, 1]
        predictions = (y_proba >= optimal_threshold).astype(int)
        
        # 5. Cr√©er le DataFrame de soumission
        submission = pd.DataFrame({
            'id': ids,
            'outcome': predictions
        })
        
        # Convertir en format attendu
        submission['outcome'] = submission['outcome'].map({0: 'noad.', 1: 'ad.'})
        
        # 6. Sauvegarder
        output_path = self.outputs_dir / "predictions" / "submission_champion.csv"
        output_path.parent.mkdir(parents=True, exist_ok=True)
        submission.to_csv(output_path, index=False)
        
        # 7. Statistiques
        logger.info("\nR√âSULTATS FINAUX")
        logger.info("-"*40)
        logger.info(f"Mod√®le : GradBoost KNN Reduced")
        logger.info(f"Seuil : {optimal_threshold:.4f}")
        logger.info(f"Total pr√©dictions : {len(submission)}")
        logger.info(f"Publicit√©s (ad.) : {np.sum(submission['outcome'] == 'ad.')} ({np.mean(submission['outcome'] == 'ad.')*100:.1f}%)")
        logger.info(f"Non-publicit√©s (noad.) : {np.sum(submission['outcome'] == 'noad.')} ({np.mean(submission['outcome'] == 'noad.')*100:.1f}%)")
        logger.info(f"\nFichier sauvegard√© : {output_path}")
        
        return submission

    # ------------------------------------------------------------------
    # Nouveau : g√©n√©ration automatique en fonction des performances
    # ------------------------------------------------------------------
    def generate_predictions_with_selected_model(self, model_name: str, imputation: str, version: str, threshold: float) -> pd.DataFrame:
        """
        G√©n√®re les pr√©dictions finales √† partir d'un mod√®le sp√©cifique, d'une m√©thode
        d'imputation et d'une variante (full/reduced), en appliquant le seuil
        optimal fourni.

        Args:
            model_name: nom du mod√®le (ex: 'randforest', 'xgboost', 'gradboost').
            imputation: m√©thode d'imputation utilis√©e ('knn' ou 'mice').
            version: version du mod√®le ('full' ou 'reduced').
            threshold: seuil de classification optimis√© √† appliquer.

        Returns:
            DataFrame de soumission avec les colonnes 'id' et 'outcome'.
        """
        logger.info("=" * 80)
        logger.info(f"G√âN√âRATION DES PR√âDICTIONS AVEC {model_name.upper()} {imputation.upper()} {version.upper()}")
        logger.info("=" * 80)

        # 1. Charger et pr√©traiter les donn√©es de test
        features, ids = self.load_and_preprocess_test_data()
        X_processed = self.apply_notebook1_preprocessing(features, imputation_method=imputation)

        # 2. D√©terminer le chemin du mod√®le
        # Plusieurs conventions possibles : best_*, pipeline_*, extensions .joblib ou .pkl
        candidates = []
        # Sans sous-dossier imputation/version (mod√®les au niveau racine)
        candidates.append(self.models_dir / f"pipeline_{model_name}_{imputation}_{version}.joblib")
        candidates.append(self.models_dir / f"pipeline_{model_name}_{imputation}_{version}.pkl")
        candidates.append(self.models_dir / f"best_{model_name}_{imputation}_{version}.joblib")
        candidates.append(self.models_dir / f"best_{model_name}_{imputation}_{version}.pkl")
        # √âventuellement sous un sous-dossier par imputation/version
        candidates.append(self.models_dir / imputation / version / f"pipeline_{model_name}_{imputation}_{version}.joblib")
        candidates.append(self.models_dir / imputation / version / f"pipeline_{model_name}_{imputation}_{version}.pkl")
        candidates.append(self.models_dir / imputation / version / f"best_{model_name}_{imputation}_{version}.joblib")
        candidates.append(self.models_dir / imputation / version / f"best_{model_name}_{imputation}_{version}.pkl")

        model_path = None
        for path in candidates:
            if path.exists():
                model_path = path
                break

        if model_path is None:
            raise FileNotFoundError(f"Aucun fichier de mod√®le trouv√© parmi : {[str(p) for p in candidates]}")

        model = joblib.load(model_path)
        logger.info(f"Mod√®le charg√© depuis : {model_path}")

        # 3. S√©lectionner les colonnes si version r√©duite
        X_final = X_processed
        if version.lower() == 'reduced':
            # Chercher le fichier de colonnes s√©lectionn√©es dans plusieurs emplacements
            sel_candidates = []
            sel_candidates.append(self.models_dir / imputation / version / f"selected_columns_{imputation}.pkl")
            sel_candidates.append(self.models_dir / imputation / version / "selected_features.pkl")
            sel_candidates.append(self.models_dir / imputation / version / "selected_columns_knn.pkl")
            sel_candidates.append(self.models_dir / imputation / version / "selected_columns_mice.pkl")
            # √âventuels chemins dans outputs/modeling/notebook2 (cas historique)
            sel_candidates.append(self.outputs_dir / "modeling" / "notebook2" / imputation / version / "selected_columns.pkl")

            selected_columns = None
            for s in sel_candidates:
                if s.exists():
                    try:
                        selected_columns = joblib.load(s)
                        break
                    except Exception:
                        continue
            if selected_columns is not None:
                selected_columns = [col for col in selected_columns if col in X_processed.columns]
                if selected_columns:
                    X_final = X_processed[selected_columns]
                    logger.info(f"Features s√©lectionn√©es : {len(selected_columns)} colonnes")
                else:
                    logger.warning("Liste de features s√©lectionn√©es vide ou aucune colonne correspondante")
            else:
                logger.warning("Fichier de colonnes s√©lectionn√©es introuvable pour version r√©duite, utilisation de toutes les colonnes")

        # 4. G√©n√©rer les probabilit√©s et les pr√©dictions
        logger.info("G√©n√©ration des pr√©dictions avec le mod√®le s√©lectionn√©‚Ä¶")
        y_proba = model.predict_proba(X_final)[:, 1]
        predictions = (y_proba >= threshold).astype(int)

        # 5. Construire le DataFrame de soumission
        submission = pd.DataFrame({
            'id': ids,
            'outcome': predictions
        })
        submission['outcome'] = submission['outcome'].map({0: 'noad.', 1: 'ad.'})

        # 6. Sauvegarder la soumission
        out_dir = self.outputs_dir / "predictions"
        out_dir.mkdir(parents=True, exist_ok=True)
        file_name = f"submission_{model_name}_{imputation}_{version}.csv"
        output_path = out_dir / file_name
        submission.to_csv(output_path, index=False)
        logger.info(f"Fichier de soumission sauvegard√© : {output_path}")

        return submission

    def generate_predictions_with_best_model_auto(self, results_csv_path: Union[str, Path]):
        """
        G√©n√®re les pr√©dictions finales en s√©lectionnant automatiquement le meilleur
        mod√®le individuel selon le F1-score indiqu√© dans un fichier CSV de
        r√©sultats de test.

        Args:
            results_csv_path: chemin vers le fichier CSV r√©sumant les performances des
                mod√®les individuels. Ce fichier doit contenir au minimum les colonnes
                suivantes : 'model', 'imputation', 'version' et 'f1' (ou 'f1_score_test')
                et 'threshold' si disponible.

        Returns:
            DataFrame de soumission g√©n√©r√©e par le meilleur mod√®le individuel.
        """
        # Charger le CSV de r√©sultats
        results_csv_path = Path(results_csv_path)
        if not results_csv_path.exists():
            logger.error(f"Fichier de r√©sultats introuvable : {results_csv_path}")
            logger.warning("Retour au mod√®le champion‚Ä¶")
            return self.generate_predictions_with_best_model()

        try:
            df = pd.read_csv(results_csv_path)
        except Exception as e:
            logger.error(f"Erreur lors du chargement du CSV {results_csv_path} : {e}")
            logger.warning("Retour au mod√®le champion‚Ä¶")
            return self.generate_predictions_with_best_model()

        # Normaliser les colonnes
        cols_lower = [c.lower() for c in df.columns]
        mapping = {c: cols_lower[i] for i, c in enumerate(df.columns)}
        # Rechercher le nom de la colonne F1
        f1_col_candidates = [c for c in df.columns if c.lower() in ['f1', 'f1_score', 'f1_score_test', 'f1_score_val']]
        if not f1_col_candidates:
            logger.error("Aucune colonne F1 trouv√©e dans le CSV de r√©sultats.")
            logger.warning("Retour au mod√®le champion‚Ä¶")
            return self.generate_predictions_with_best_model()
        f1_col = f1_col_candidates[0]

        # Trier par F1 d√©croissant et choisir la premi√®re ligne
        df_sorted = df.sort_values(by=f1_col, ascending=False).reset_index(drop=True)
        best_row = df_sorted.iloc[0]
        model = str(best_row.get('model', '')).lower()
        imputation = str(best_row.get('imputation', '')).lower()
        version = str(best_row.get('version', '')).lower()
        threshold = best_row.get('threshold', None)

        if threshold is None or pd.isna(threshold):
            # Default threshold if missing
            logger.warning("Seuil non trouv√© dans le CSV, utilisation de 0.5")
            threshold = 0.5

        logger.info(f"Meilleur mod√®le s√©lectionn√© : {model} {imputation} {version} (F1={best_row[f1_col]:.4f}, seuil={threshold})")
        return self.generate_predictions_with_selected_model(model, imputation, version, float(threshold))

    def generate_predictions_with_stacking_auto(self, stacking_dir: Union[str, Path]):
        """
        G√©n√®re les pr√©dictions finales en s√©lectionnant automatiquement le meilleur
        stacking (sans refit) parmi les fichiers JSON pr√©sents dans un dossier.

        Args:
            stacking_dir: chemin vers le dossier contenant les fichiers JSON de stacking.
                Chaque fichier doit contenir les cl√©s 'performance' et 'threshold'.

        Returns:
            DataFrame de soumission g√©n√©r√©e par le meilleur stacking.
        """
        stacking_dir = Path(stacking_dir)
        logger.info(f"Recherche du dossier de stacking : {stacking_dir}")
        logger.info(f"Dossier existe : {stacking_dir.exists()}")
        logger.info(f"Est un dossier : {stacking_dir.is_dir() if stacking_dir.exists() else 'N/A'}")
        
        if not stacking_dir.exists() or not stacking_dir.is_dir():
            logger.error(f"Dossier de stacking introuvable : {stacking_dir}")
            logger.warning("Retour au stacking par d√©faut‚Ä¶")
            return self.generate_predictions_with_stacking()

        best_f1 = -1
        best_threshold = None
        best_suffix = None
        best_data = None
        # Lister tous les fichiers JSON
        json_files = list(stacking_dir.glob("*.json"))
        logger.info(f"Fichiers JSON trouv√©s : {[f.name for f in json_files]}")
        
        # Parcourir tous les fichiers JSON de stacking
        for json_file in json_files:
            if "stacking" not in json_file.name.lower():
                continue
            try:
                with open(json_file, 'r') as f:
                    data = json.load(f)
                perf = data.get('performance', {})
                # Chercher F1 test ou F1 val
                f1 = perf.get('f1_score_test') or perf.get('f1_score_val') or perf.get('f1')
                threshold = data.get('threshold') or data.get('optimal_threshold')
                if f1 is not None and threshold is not None and float(f1) > best_f1:
                    best_f1 = float(f1)
                    best_threshold = float(threshold)
                    best_data = data
                    # suffix identifie le type : knn ou mice
                    # Exemple de fichier : stacking_no_refit_knn_full.json
                    name = json_file.name
                    if 'knn' in name:
                        best_suffix = 'knn'
                    elif 'mice' in name:
                        best_suffix = 'mice'
                    else:
                        best_suffix = None
                    logger.info(f"Nouveau meilleur stacking : {best_suffix} (F1={best_f1:.4f}, seuil={best_threshold})")
            except Exception:
                continue

        if best_f1 == -1 or best_suffix is None or best_data is None:
            logger.error("Aucun fichier de stacking valide trouv√©.")
            logger.warning("Retour au stacking par d√©faut‚Ä¶")
            return self.generate_predictions_with_stacking()

        logger.info(f"Meilleur stacking : {best_suffix.upper()} (F1={best_f1:.4f}, seuil={best_threshold})")
        
        # Utiliser directement les pr√©dictions sauvegard√©es dans le JSON
        return self.create_submission_from_stacking_results(best_data, best_threshold)

        # 1. Charger et pr√©traiter les donn√©es
        features, ids = self.load_and_preprocess_test_data()
        X_knn = self.apply_notebook1_preprocessing(features, imputation_method="knn")
        X_mice = self.apply_notebook1_preprocessing(features, imputation_method="mice")
        
        # 2. Charger les mod√®les de stacking (avec refit ou sans refit, on utilise ceux de notebook3)
        # On cherche d'abord dans outputs/modeling/notebook3/stacking
        default_dir = self.outputs_dir / "modeling" / "notebook3" / "stacking"
        stacking_knn_path = default_dir / "stacking_knn_with_refit.joblib"
        stacking_mice_path = default_dir / "stacking_mice_with_refit.joblib"
        if not stacking_knn_path.exists() or not stacking_mice_path.exists():
            # Fallback vers models_dir/notebook3/stacking
            alt_dir = self.models_dir / "notebook3" / "stacking"
            stacking_knn_path = alt_dir / "stacking_knn_with_refit.joblib"
            stacking_mice_path = alt_dir / "stacking_mice_with_refit.joblib"
        
        if not stacking_knn_path.exists() or not stacking_mice_path.exists():
            logger.warning("Mod√®les de stacking non trouv√©s, retour au stacking par d√©faut‚Ä¶")
            return self.generate_predictions_with_stacking()
        
        stacking_knn = joblib.load(stacking_knn_path)
        stacking_mice = joblib.load(stacking_mice_path)
        
        # 3. G√©n√©rer les probabilit√©s et les pr√©dictions
        proba_knn = stacking_knn.predict_proba(X_knn)[:, 1]
        proba_mice = stacking_mice.predict_proba(X_mice)[:, 1]
        proba_final = 0.5 * proba_knn + 0.5 * proba_mice
        predictions = (proba_final >= best_threshold).astype(int)
        
        # 4. Construire la soumission
        submission = pd.DataFrame({
            'id': ids,
            'outcome': predictions
        })
        submission['outcome'] = submission['outcome'].map({0: 'noad.', 1: 'ad.'})
        
        out_dir = self.outputs_dir / "predictions"
        out_dir.mkdir(parents=True, exist_ok=True)
        output_path = out_dir / f"submission_stacking_{best_suffix}.csv"
        submission.to_csv(output_path, index=False)
        logger.info(f"Fichier de soumission sauvegard√© : {output_path}")
        return submission
    
    def generate_predictions_with_stacking(self):
        """
        G√©n√®re les pr√©dictions avec le mod√®le de stacking.
        """
        logger.info("="*80)
        logger.info("G√âN√âRATION DES PR√âDICTIONS AVEC STACKING")
        logger.info("="*80)
        
        # 1. Charger et pr√©traiter les donn√©es pour KNN et MICE
        features, ids = self.load_and_preprocess_test_data()
        X_knn = self.apply_notebook1_preprocessing(features, imputation_method="knn")
        X_mice = self.apply_notebook1_preprocessing(features, imputation_method="mice")
        
        # 2. Charger les mod√®les de stacking
        stacking_knn_path = self.outputs_dir / "modeling" / "notebook3" / "stacking" / "stacking_knn_with_refit.joblib"
        stacking_mice_path = self.outputs_dir / "modeling" / "notebook3" / "stacking" / "stacking_mice_with_refit.joblib"
        
        if not stacking_knn_path.exists() or not stacking_mice_path.exists():
            logger.warning("Mod√®les de stacking non trouv√©s, utilisation du mod√®le champion")
            return self.generate_predictions_with_best_model()
        
        stacking_knn = joblib.load(stacking_knn_path)
        stacking_mice = joblib.load(stacking_mice_path)
        
        # 3. G√©n√©rer les pr√©dictions
        logger.info("G√©n√©ration des pr√©dictions avec stacking...")
        proba_knn = stacking_knn.predict_proba(X_knn)[:, 1]
        proba_mice = stacking_mice.predict_proba(X_mice)[:, 1]
        
        # Moyenne pond√©r√©e
        proba_final = 0.5 * proba_knn + 0.5 * proba_mice
        
        # Seuil optimal pour le stacking (bas√© sur vos r√©sultats)
        optimal_threshold = 0.42
        predictions = (proba_final >= optimal_threshold).astype(int)
        
        # 4. Cr√©er et sauvegarder la soumission
        submission = pd.DataFrame({
            'id': ids,
            'outcome': predictions
        })
        submission['outcome'] = submission['outcome'].map({0: 'noad.', 1: 'ad.'})
        
        output_path = self.outputs_dir / "predictions" / "submission_stacking.csv"
        output_path.parent.mkdir(parents=True, exist_ok=True)
        submission.to_csv(output_path, index=False)
        
        logger.info(f"\nFichier sauvegard√© : {output_path}")
        return submission

    def create_submission_from_stacking_results(self, stacking_data: dict, threshold: float) -> pd.DataFrame:
        """
        Cr√©e une soumission directement √† partir des r√©sultats de stacking sauvegard√©s.
        
        Args:
            stacking_data: Donn√©es JSON du stacking (avec pr√©dictions)
            threshold: Seuil optimal √† appliquer
            
        Returns:
            DataFrame de soumission
        """
        logger.info("Cr√©ation de la soumission √† partir des r√©sultats de stacking...")
        
        # Extraire les probabilit√©s de test
        predictions_data = stacking_data.get('predictions', {})
        # Supporte diff√©rentes cl√©s : "test_proba" (nouvelle) ou "test" (ancienne)
        test_proba = predictions_data.get('test_proba')
        if not test_proba:
            test_proba = predictions_data.get('test')

        if not test_proba:
            logger.error("Aucune probabilit√© de test trouv√©e dans les donn√©es de stacking")
            return self.generate_predictions_with_stacking()

        # Appliquer le seuil
        predictions = (np.array(test_proba) >= threshold).astype(int)

        # Cr√©er les IDs (utiliser ceux fournis si disponibles)
        num_predictions = len(predictions)
        ids = stacking_data.get('test_ids')
        if not ids or len(ids) != num_predictions:
            ids = list(range(num_predictions))
        
        # Cr√©er la soumission
        submission = pd.DataFrame({
            'id': ids,
            'outcome': predictions
        })
        submission['outcome'] = submission['outcome'].map({0: 'noad.', 1: 'ad.'})
        
        # Sauvegarder
        output_path = self.outputs_dir / "predictions" / "submission_stacking_auto.csv"
        output_path.parent.mkdir(parents=True, exist_ok=True)
        submission.to_csv(output_path, index=False)
        
        # Statistiques
        logger.info("R√âSULTATS FINAUX STACKING")
        logger.info("-" * 40)
        logger.info(f"M√©thode : {stacking_data.get('method', 'Stacking')}")
        logger.info(f"Seuil : {threshold:.4f}")
        logger.info(f"Total pr√©dictions : {len(submission)}")
        logger.info(f"Publicit√©s (ad.) : {np.sum(submission['outcome'] == 'ad.')} ({np.mean(submission['outcome'] == 'ad.')*100:.1f}%)")
        logger.info(f"Non-publicit√©s (noad.) : {np.sum(submission['outcome'] == 'noad.')} ({np.mean(submission['outcome'] == 'noad.')*100:.1f}%)")
        logger.info(f"Fichier sauvegard√© : {output_path}")
        
        return submission

# Fonction principale
def generate_final_predictions(
    use_stacking: bool = False,
    auto_select: bool = False,
    results_csv_path: Optional[Union[str, Path]] = None,
    stacking_dir: Optional[Union[str, Path]] = None,
    base_dir: Optional[Union[str, Path]] = None,
) -> pd.DataFrame:
    """
    G√©n√®re les pr√©dictions finales avec les vrais mod√®les.

    Args:
        use_stacking: Si True, utilise le stacking. Sinon, utilise un mod√®le individuel.
        auto_select: Si True, s√©lectionne automatiquement le meilleur mod√®le/stacking en
            fonction des performances enregistr√©es. Si False, utilise le mod√®le
            champion cod√© en dur ou le stacking par d√©faut.
        results_csv_path: Chemin vers le CSV des r√©sultats des mod√®les individuels.
            Utilis√© uniquement si auto_select=True et use_stacking=False. Par d√©faut,
            cherche ``outputs/modeling/test_results_all_models.csv``.
        stacking_dir: Dossier contenant les JSON de stacking. Utilis√© uniquement
            si auto_select=True et use_stacking=True. Par d√©faut,
            cherche ``artifacts/models/notebook3/stacking``.
        base_dir: R√©pertoire racine du projet. Par d√©faut ``'.'``.

    Returns:
        DataFrame contenant les pr√©dictions finales.
    """
    # Instancier le pipeline avec le r√©pertoire de base
    pipeline = PredictionPipeline(base_dir=base_dir or ".")

    if auto_select:
        if use_stacking:
            # S√©lection automatique du meilleur stacking
            # D√©terminer le dossier par d√©faut si stacking_dir non fourni
            if stacking_dir is None:
                # Pr√©f√©rence pour outputs/modeling/notebook3/stacking
                default_dir = pipeline.outputs_dir / "modeling" / "notebook3" / "stacking"
                if not default_dir.exists():
                    # Essayer artifacts/models/notebook3/stacking
                    default_dir = pipeline.base_dir / "artifacts" / "models" / "notebook3" / "stacking"
                    if not default_dir.exists():
                        default_dir = pipeline.models_dir / "notebook3" / "stacking"
                stacking_dir = default_dir
            else:
                # Si stacking_dir est fourni comme chemin relatif, le r√©soudre depuis base_dir
                stacking_dir = Path(stacking_dir)
                if not stacking_dir.is_absolute():
                    stacking_dir = pipeline.base_dir / stacking_dir
            return pipeline.generate_predictions_with_stacking_auto(stacking_dir)
        else:
            # S√©lection automatique du meilleur mod√®le individuel
            if results_csv_path is None:
                # Chemin par d√©faut vers test_results_all_models.csv
                default_csv = pipeline.outputs_dir / "modeling" / "test_results_all_models.csv"
                # Fallback vers cross_validation_results.csv si le premier n'existe pas
                if not default_csv.exists():
                    default_csv = pipeline.outputs_dir / "modeling" / "cross_validation_results.csv"
                results_csv_path = default_csv
            return pipeline.generate_predictions_with_best_model_auto(results_csv_path)
    else:
        # Pas d'auto-s√©lection
        if use_stacking:
            return pipeline.generate_predictions_with_stacking()
        else:
            return pipeline.generate_predictions_with_best_model()

def create_submission_with_full_test_data(method="stacking_with_refit_mice"):
    """
    G√©n√®re un fichier de soumission en utilisant les donn√©es de test compl√®tes (820 √©chantillons).
    Utilise les r√©sultats JSON stock√©s plut√¥t que de recharger les mod√®les.
    
    Args:
        method: M√©thode de stacking √† utiliser ("stacking_with_refit_mice" ou "stacking_with_refit_knn")
    
    Returns:
        DataFrame: Soumission avec exactement 820 pr√©dictions
    """
    import pandas as pd
    import json
    from pathlib import Path
    
    # Charger les donn√©es de test compl√®tes
    test_data_path = cfg.paths.data / "raw" / "data_test.csv"
    if not test_data_path.exists():
        raise FileNotFoundError(f"Fichier de test introuvable : {test_data_path}")
    
    test_data = pd.read_csv(test_data_path)
    logger.info(f"üìä Donn√©es de test charg√©es : {test_data.shape}")
    
    # Charger les r√©sultats JSON du stacking
    stacking_results_path = cfg.paths.artifacts / "models" / "notebook3" / "stacking" / f"{method}.json"
    
    if not stacking_results_path.exists():
        raise FileNotFoundError(f"R√©sultats de stacking introuvables : {stacking_results_path}")
    
    with open(stacking_results_path, 'r') as f:
        results = json.load(f)
    
    # V√©rifier que nous avons les bonnes pr√©dictions
    if "predictions" not in results or "test_pred" not in results["predictions"]:
        raise ValueError(f"Pr√©dictions manquantes dans {stacking_results_path}")
    
    predictions = results["predictions"]["test_pred"]
    
    # V√©rifier la coh√©rence avec les donn√©es de test
    if len(predictions) != len(test_data):
        logger.warning(f"‚ö†Ô∏è D√©saccord: {len(predictions)} pr√©dictions vs {len(test_data)} √©chantillons de test")
        
        # Si on a moins de pr√©dictions que d'√©chantillons de test, on utilise les donn√©es disponibles
        if len(predictions) < len(test_data):
            logger.info(f"üìä Troncature des donn√©es de test √† {len(predictions)} √©chantillons")
            test_data = test_data.iloc[:len(predictions)]
        else:
            # Si on a plus de pr√©dictions, on tronque les pr√©dictions
            logger.info(f"üìä Troncature des pr√©dictions √† {len(test_data)} √©chantillons")
            predictions = predictions[:len(test_data)]
    
    # Cr√©er le DataFrame de soumission
    submission = pd.DataFrame({
        'id': range(len(predictions)),
        'outcome': ['ad.' if pred == 1 else 'noad.' for pred in predictions]
    })
    
    # Sauvegarder
    output_dir = cfg.paths.outputs / "predictions"
    output_dir.mkdir(parents=True, exist_ok=True)
    output_path = output_dir / f"submission_{method}_full.csv"
    
    submission.to_csv(output_path, index=False)
    logger.info(f"üìù Fichier de soumission sauvegard√© : {output_path}")
    logger.info(f"üìä {len(submission)} pr√©dictions g√©n√©r√©es")
    logger.info(f"üìà R√©partition: {sum(predictions)} 'ad.' ({100*sum(predictions)/len(predictions):.1f}%), {len(predictions)-sum(predictions)} 'noad.' ({100*(len(predictions)-sum(predictions))/len(predictions):.1f}%)")
    
    return submission

if __name__ == "__main__":
    # G√©n√©rer avec le mod√®le champion
    submission = generate_final_predictions(use_stacking=False)
    print("\n‚úÖ Pr√©dictions g√©n√©r√©es avec le mod√®le champion !")